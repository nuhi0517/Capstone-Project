{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZqhnpOQLqiGgd31WuGT3HgMmS7tcPqTj",
      "authorship_tag": "ABX9TyMpp2OUSuERm5IP+I2TO6mY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuhi0517/Capstone-Project/blob/main/Medical_Insurance_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd9_lv59zFfO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Capstone_Project_Medical_Insurance_Price_Prediction"
      ],
      "metadata": {
        "id": "bh8EOyMl0XI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Capstone_Project_Medical_Insurance_Price_Prediction"
      ],
      "metadata": {
        "id": "U0uhK803wvwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Project is based on Medical Insurance Price Prediction data available from kaggle repository.\n",
        "\n",
        "(https://www.kaggle.com/code/dylandsi/medical-insurance-price-prediction)\n",
        "\n",
        "1. It contains the details (e,g, age, sex, bmi etc.)of 2773 customers.\n",
        "2. My project task is to create a machine learning model which can predict the average price of insurance based on its characteristics.\n",
        "3. For solving this problem, I will approach the task, with a step by step approach to create a data analysis and prediction model based on (machine learning/AI algorithms, regression algorith for example) available from different Python packages, modules and classes."
      ],
      "metadata": {
        "id": "ctWfEUgGFiwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Reading the dataset**"
      ],
      "metadata": {
        "id": "uRV_EV5UFx8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supressing the warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "IeYZ4-ne6jWe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading and Checking the Data:**\n",
        "\n",
        "Load the data into a table using pandas, a tool for data analysis. Look at the first few rows to see what the data looks like and what kind of information it holds. Make sure there are no missing entries in the data. If there are any, you can either fill them in with appropriate values or remove parts of the data that are incomplete. Also, look for any odd or unusual data points that might need fixing."
      ],
      "metadata": {
        "id": "zjrHIN_WYZ9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the dataset file is named \"MedicalInsuranceData.csv\" and is located in the current directory\n",
        "MedicalInsuranceData = pd.read_csv('Medical_insurance.csv')\n",
        "\n",
        "# Printing the shape of the dataset before removing duplicates\n",
        "print('Shape before deleting duplicate values:', MedicalInsuranceData.shape)\n",
        "\n",
        "# Removing duplicate rows if any\n",
        "MedicalInsuranceData = MedicalInsuranceData.drop_duplicates()\n",
        "\n",
        "# Printing the shape of the dataset after removing duplicates\n",
        "print('Shape After deleting duplicate values:', MedicalInsuranceData.shape)\n",
        "\n",
        "# Printing sample data\n",
        "# Start observing the Quantitative/Categorical/Qualitative variables\n",
        "MedicalInsuranceData.head(10)\n",
        "\n"
      ],
      "metadata": {
        "id": "heAE46Oj1dkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key observations from step 1 about Data Description**\n",
        "\n",
        "1. The file contains 2773 medical details from the Medical Insurance dataset.\n",
        "2. There are 7 attributes.\n",
        "3. Attributes from the dataset are: **age, sex, bmi, children, smoker, region and charges.**\n",
        "4. BMI- Body Mass Index.\n",
        "5. Shape before deleting duplicate values: (2772, 7).\n",
        "6. Shape after deleting duplicate values: (1337, 7).\n"
      ],
      "metadata": {
        "id": "FiMFM2Ol9PJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 : Problem Statement Definition**\n",
        "\n",
        "Create a machine learning model that can guess how much individuals will spend on medical care based on factors like their age, gender, body weight, number of children, whether they smoke, and where they live. This model should help an insurance company decide how much to charge new customers by giving them a good idea of the potential health costs.\n",
        "\n"
      ],
      "metadata": {
        "id": "HaR8xvnb89ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target variable identification**"
      ],
      "metadata": {
        "id": "TCBhanFz9G3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the medical insurance dataset\n",
        "insurance_data = pd.read_csv('/content/drive/MyDrive/Medical_insurance.csv')\n",
        "\n",
        "# Check column names\n",
        "print(insurance_data.columns)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(insurance_data.head())\n",
        "\n",
        "# Extract the target variable if the column name is correct\n",
        "if 'charges' in insurance_data.columns:\n",
        "    target_variable = insurance_data['charges']\n",
        "    print(target_variable)\n",
        "else:\n",
        "    print(\"Column 'charges' not found in the dataset.\")"
      ],
      "metadata": {
        "id": "OH44s80yYxC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style of seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a figure and axis object\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the distribution of charges\n",
        "sns.histplot(insurance_data['charges'], kde=True, color='skyblue')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Distribution of Medical Charges')\n",
        "plt.xlabel('Charges')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3m9rdfNSZBZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Choosing the appropriate ML/AI Algorithm for Data Analysis**"
      ],
      "metadata": {
        "id": "GDbMeMamZJ9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "insurance_data = pd.read_csv('/content/drive/MyDrive/Medical_insurance.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "# Handle missing values, encode categorical variables, scale features if necessary\n",
        "\n",
        "# Drop rows with missing values\n",
        "insurance_data.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "insurance_data = pd.get_dummies(insurance_data, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
        "\n",
        "# Split data into features and target variable\n",
        "X = insurance_data.drop(columns=['charges'])  # Features\n",
        "y = insurance_data['charges']  # Target variable\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features if necessary\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train regression models\n",
        "# Example 1: Linear Regression\n",
        "linear_regression_model = LinearRegression()\n",
        "linear_regression_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Example 2: Random Forest Regression\n",
        "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "linear_regression_pred = linear_regression_model.predict(X_test_scaled)\n",
        "random_forest_pred = random_forest_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate models\n",
        "linear_regression_mse = mean_squared_error(y_test, linear_regression_pred)\n",
        "random_forest_mse = mean_squared_error(y_test, random_forest_pred)\n",
        "\n",
        "print('Linear Regression Mean Squared Error:', linear_regression_mse)\n",
        "print('Random Forest Mean Squared Error:', random_forest_mse)\n"
      ],
      "metadata": {
        "id": "ApEBgE4MZ7E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualising the distribution of Target variable**\n",
        "\n",
        "This code will make a chart (histogram) that displays how medical costs are spread out among the people in the dataset. You can change the number of categories (bins) and the color to make the chart clearer."
      ],
      "metadata": {
        "id": "CR7Vfic0bDoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the medical insurance dataset\n",
        "insurance_data = pd.read_csv('Medical_insurance.csv')\n",
        "\n",
        "# Define numerical and categorical columns\n",
        "numerical_columns = ['age', 'bmi', 'children', 'charges']\n",
        "categorical_columns = ['sex', 'smoker', 'region']\n",
        "\n",
        "# Explore the distributions of variables through visualizations\n",
        "# Histograms for numerical variables\n",
        "insurance_data[numerical_columns].hist(bins=20, figsize=(15, 10))\n",
        "plt.suptitle('Histograms of Numerical Variables', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Box plots for numerical variables\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.boxplot(data=insurance_data[numerical_columns])\n",
        "plt.title('Box Plots of Numerical Variables', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot for BMI vs. Charges\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='bmi', y='charges', data=insurance_data)\n",
        "plt.title('Scatter Plot of BMI vs. Charges', fontsize=16)\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Charges')\n",
        "plt.show()\n",
        "\n",
        "# Investigate correlations between numerical variables\n",
        "correlation_matrix = insurance_data[numerical_columns].corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Numerical Variables', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Box plots for numerical and categorical variables\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.boxplot(data=insurance_data[numerical_columns + categorical_columns])\n",
        "plt.title('Box Plots of Numerical and Categorical Variables', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jlk2nysmbPc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Looking at the class distribution (Target variable distribution to check if the data is balanced or skewed)**\n",
        "\n",
        "1. If target variable's distribution is too skewed then the predictive modeling will lead to poor results.\n",
        "2. Ideally Bell curve is desirable but slightly positive skew or negative skew is also fine.\n",
        "3. When performing Regression algorithm modelling and analysis, we need to make sure the histogram looks like a bell curve or slight skewed version of it.\n",
        "4. Otherwise it impacts the Machine Learning algorithms ability to learn all the scenarios from the data.\n"
      ],
      "metadata": {
        "id": "CaMt1MDcn1y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have loaded the medical insurance dataset into a variable named 'insurance_data'\n",
        "# Replace 'insurance_data' with the appropriate variable name if it's different\n",
        "insurance_data['charges'].hist()\n",
        "plt.title('Distribution of Medical Expenses (Charges)')\n",
        "plt.xlabel('Charges')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AGId1VNioHIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 4**\n",
        "\n",
        "1. The way the target variable is spread out in the data is good enough to continue.\n",
        "2. There are enough examples of each type of value for effective learning."
      ],
      "metadata": {
        "id": "bmRMxEH5pWH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Data exploration at basic level**\n",
        "\n",
        "1. This step is performed to guage the overall data.\n",
        "2. The volume of data, the types of columns present in the data.\n",
        "3. Initial assessment of the data should be done to identify which columns are Quantitative, Categorical or Qualitative.\n",
        "4. This step helps to start the column/data rejection process.\n",
        "5. For example in this dataset, you will ask, does this column affect the price of the house?\n",
        "6. If the answer is a clear \"No\", then remove the column immediately from the data, otherwise keep the column for further analysis.\n",
        "7. There are four commands which are used for Basic data exploratory Analysis in Python:\n",
        "* head() : This helps to see a few sample rows of the data\n",
        "* info() : This provides the summarized information of the data\n",
        "* describe() : This provides the descriptive statistical details of the data\n",
        "* nunique(): This helps us to identify if a column is categorical or continuous\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EYR_HAGjqpP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at sample rows in the data\n",
        "insurance_data.head()"
      ],
      "metadata": {
        "id": "crUYu0HvrkUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at sample rows in the data\n",
        "insurance_data.tail()"
      ],
      "metadata": {
        "id": "FzaQsC6TzRof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observing the summarized information of data\n",
        "# Data types, Missing values based on number of non-null values Vs total rows etc.\n",
        "# Remove those variables from data which have too many missing values (Missing Values > 30%)\n",
        "# Remove Qualitative variables which cannot be used in Machine Learning\n",
        "insurance_data.info()"
      ],
      "metadata": {
        "id": "VXlMbdzgzXq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at the descriptive statistics of the data\n",
        "insurance_data.describe(include='all')"
      ],
      "metadata": {
        "id": "NI-6ivfzzbA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finging unique values for each column\n",
        "# TO understand which column is categorical and which one is Continuous\n",
        "# Typically if the numer of unique values are < 20 then the variable is likely to be a category otherwise continuous\n",
        "insurance_data.nunique()"
      ],
      "metadata": {
        "id": "KeEV5ttIzi0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 5**\n",
        "\n",
        "* Based on the basic exploration above, you can now create a simple report of the data, noting down your observations regaring each column.\n",
        "* Hence, creating a initial roadmap for further analysis.\n",
        "* The selected columns in this step are not final, further study will be done and then a final list will be created.\n",
        "*   age - Continuous. Selected.\n",
        "*   sex - Categorical. Selected.\n",
        "*   bmi - Continuous. Selected.\n",
        "*   children - Categorical. Selected.\n",
        "*  smoker - Categorical. Selected.\n",
        "*  region - Categorical. Selected.\n",
        "* charges - Continuous. Selected. This is the Target or Class Variable, which needs to be predicted by the proposed regression model!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Iw4DwtMizt7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Identifying and Rejecting useless columns**\n",
        "\n",
        "1. There are no qualitative columns in the data.\n",
        "2. Hence no need to remove any column.\n"
      ],
      "metadata": {
        "id": "d0wJMFL-1DPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Visual Exploratory Data Analysis of data (with Histogram\n",
        "and Barcharts)**\n",
        "\n",
        "1. Visualize distribution of all the Categorical Predictor variables in the data using bar plots.\n",
        "2. We can spot a categorical variable in the data by looking at the unique values in them.\n",
        "3. Typically a categorical variable contains less than 20 Unique values AND there is repetition of values, which means the data can be grouped by those unique values.\n",
        "4. Based on the Basic Exploration Data Analysis in the previous step, we could spotted two categorical predictors in the data\n",
        "5. Categorical Predictors:\n",
        "*   'sex'\n",
        "*   'children'\n",
        "*   'smoker'\n",
        "*   'region'\n",
        "6. We will use bar charts to see how the data is distributed for these categorical columns."
      ],
      "metadata": {
        "id": "XqyYMFvl5Z40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting multiple bar charts at once for categorical variables\n",
        "# Since there is no default function which can plot bar charts for multiple columns at once\n",
        "# we are defining our own function for the same\n",
        "\n",
        "def PlotBarCharts(inpData, colsToPlot):\n",
        "    %matplotlib inline\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Generating multiple subplots\n",
        "    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))\n",
        "    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n",
        "\n",
        "    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n",
        "        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])"
      ],
      "metadata": {
        "id": "JzPJ4_9n8h8x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################################\n",
        "# Calling the function PlotBarCharts() we have created\n",
        "PlotBarCharts(inpData=insurance_data, colsToPlot=['sex','children','smoker','region'])"
      ],
      "metadata": {
        "id": "oMSbXgJR8nmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 7**\n",
        "\n",
        "1. Bar charts help analyze data by showing different categories on the X-axis and their frequencies on the Y-axis.\n",
        "2. In an ideal scenario, each category would have a similar number of instances, making the data useful for machine learning algorithms.\n",
        "3. A bar chart that is skewed, where one category dominates over others, indicates an imbalance that might not be helpful for building machine learning models.\n",
        "4. As we move into analyzing correlations, we can decide whether to keep or remove such imbalanced data attributes.\n",
        "5. Notably, the \"sex\" and \"smoker\" categories in the dataset are biased, with one category significantly outnumbering the other.\n",
        "6. These skewed categories may not provide valuable information for predicting the target variable since the imbalance doesn't offer diverse data for the algorithms to learn from.\n",
        "7. We've selected 'sex', 'children', 'smoker', and 'region' as some of the categorical variables to examine further. Two of these will be analyzed in more detail to understand their impact on the model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QPqs8WEL9G5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Now Visualize distribution of all the Continuous Predictor variables in the data using\n",
        "histograms**\n",
        "\n",
        "Based on the Basic Exploratory Data Analysis, there are three continuous predictor variables 'age', 'bmi', 'charges'."
      ],
      "metadata": {
        "id": "T6HO9MzfE-Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting histograms of multiple columns together\n",
        "insurance_data.hist(['age', 'bmi', 'charges'], figsize=(18,10))"
      ],
      "metadata": {
        "id": "hM9Vnr4rF3_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 8**\n",
        "\n",
        "1. Histogram Interpretation\n",
        "2. Each histograms shows us the data distribution for a single continuous variable.\n",
        "3. The X-axis shows the range of values and Y-axis represent the number of values in that range.\n",
        "4. For example, in the above histogram of \"AGE\", there are around 200 rows in data that has age value between 90 to 100.\n",
        "5. The age histogram does not display a bell curve; instead, it shows a relatively even distribution across different age groups until it declines sharply after age 60.\n",
        "6. The BMI histogram is bell-shaped but leans right, concentrating in the mid to high range, while the Charges histogram is significantly right-skewed, common in financial data where many observations are low and few are high.\n",
        "7. If there is too much skewness, then outlier removal treatment should be done and the column should be re-examined, and if that also does not solve the problem then only reject the column/data attribute.\n",
        "8. Selected Continuous Variables:\n",
        "* age\n",
        "* bmi  \n",
        "* charges  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BXrqJV1i4bj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection based on data distribution**\n"
      ],
      "metadata": {
        "id": "xhm06aeWGwyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load the dataset\n",
        "insurance_data = pd.read_csv('Medical_insurance.csv')\n",
        "\n",
        "# Visualize data distributions\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.histplot(insurance_data['age'], kde=True, color='blue', bins=30)\n",
        "plt.title('Histogram of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PQf3wRufISRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load the dataset\n",
        "insurance_data = pd.read_csv('Medical_insurance.csv')\n",
        "\n",
        "# Perform one-hot encoding for categorical variables\n",
        "categorical_columns = ['sex', 'smoker', 'region']  # Ensure column names are lowercase\n",
        "insurance_data_encoded = pd.get_dummies(insurance_data, columns=categorical_columns)\n",
        "\n",
        "# Define features and target variable\n",
        "X = insurance_data_encoded.drop(columns=['charges'])  # Features\n",
        "y = insurance_data_encoded['charges']  # Target variable\n",
        "\n",
        "# Use statistical tests to determine feature importance\n",
        "selector = SelectKBest(score_func=f_classif, k='all')\n",
        "selector.fit(X, y)\n",
        "feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': selector.scores_})\n",
        "feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
        "print(\"Feature Importance Scores:\")\n",
        "print(feature_scores)\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Score', y='Feature', data=feature_scores, palette='viridis')\n",
        "plt.title('Feature Importance Scores')\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# Select top k features based on importance scores\n",
        "k = 5  # Example: Select top 5 features\n",
        "selected_features = feature_scores['Feature'].head(k).tolist()\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# Train a machine learning model using selected features\n",
        "X_selected = X[selected_features]\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_selected, y)\n"
      ],
      "metadata": {
        "id": "OsigkKlLJCmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Outlier Analysis**\n",
        "\n",
        "1. Outliers are extreme values in the data which are far away from most of the values.\n",
        "2. You can see them as the tails in the histogram.\n",
        "3. Outlier must be treated one column/data attribute at a time.\n",
        "4. As the treatment will be slightly different for each column.\n",
        "5. Outliers bias the building of machine learning models.\n",
        "6. As the algorithm tries to fit the extreme value, it goes away from majority of the data.\n",
        "7. Outlined below are two options to treat outliers in the data.\n",
        "8. Option-1: Delete the outlier Records. Only if there are just few rows lost.\n",
        "9. Option-2: Impute the outlier values with a logical business value.\n",
        "10. Let us find out the most logical value to be replaced in place of outliers by looking at the histogram.\n"
      ],
      "metadata": {
        "id": "0_s-pyE0JxMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing outliers for 'charges'\n",
        "# Finding nearest values to 6500 mark\n",
        "insurance_data[insurance_data['charges']<6500].sort_values(by='charges',ascending=False)"
      ],
      "metadata": {
        "id": "r5gy9gPCLlL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Above result shows the nearest logical value is 6496.8860, hence, replacing any value above 6500 with it.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zaj7nxwC0HhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing outliers with nearest possibe value\n",
        "insurance_data['charges'][insurance_data['charges']>6500] =6496.8860"
      ],
      "metadata": {
        "id": "DYm0vnzG0J2-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10: Removal of Outliers and Missing Values**\n"
      ],
      "metadata": {
        "id": "pdAJXitfL2V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_data.hist(['charges'], figsize=(18,5))"
      ],
      "metadata": {
        "id": "NwTEdhke3PQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 10**\n",
        "\n",
        "1. The distribution has improved after the outlier treatment.\n",
        "2. There is still a tail but it is thick, that means there are many values in that range, hence, it is acceptable.\n"
      ],
      "metadata": {
        "id": "crhp93tlOiL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 11: Missing Value Analysis**\n",
        "\n",
        "1. Missing values are treated for each column separately.\n",
        "2. If a column has more than 30% data missing, then missing value treatment cannot be done.\n",
        "3. That column must be rejected because too much information is missing.\n",
        "4. Outlined below are some options for treating missing values in data.\n",
        "5. Delete the missing value rows if there are only few records.\n",
        "6. Impute the missing values with MEDIAN value for continuous variables.\n",
        "7. Impute the missing values with MODE value for categorical variables.\n",
        "8. Interpolate the values based on nearby values.\n",
        "9. Interpolate the values based on business logic."
      ],
      "metadata": {
        "id": "kCOMCLBi4Fm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding how many missing values are there for each column\n",
        "insurance_data.isnull().sum()"
      ],
      "metadata": {
        "id": "jQWiNomD4eBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 11**\n",
        "\n",
        "1. No missing values in this data!\n",
        "2. So no removal of any data samples(rows) is needed."
      ],
      "metadata": {
        "id": "3ECO_4X-4vCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 12: Feature Selection (Attribute Selection)**\n",
        "\n",
        "1. Now its time to finally choose the best columns(Features) which are correlated to the Target variable.\n",
        "2. This can be done directly by measuring the correlation values or ANOVA analysis or Chi-Square tests.\n",
        "3. However, it is always helpful to visualize the relation between the Target variable/class variable and each of the predictors(features) to get a better sense of data.\n",
        "4. Listed below are some of the techniques used for visualizing relationship between two variables as well as measuring the strength statistically.\n",
        "* **Visual exploration of relationship between variables**\n",
        "1. Continuous Vs Continuous ---- Scatter Plot\n",
        "2. Categorical Vs Continuous---- Box Plot\n",
        "3. Categorical Vs Categorical---- Grouped Bar Plots\n",
        "4. Statistical measurement of relationship strength between variables\n",
        "5. Continuous Vs Continuous ---- Correlation matrix\n",
        "6. Categorical Vs Continuous---- ANOVA test\n",
        "7. Categorical Vs Categorical--- Chi-Square test\n",
        "* **For this dataset, the Target variable is Continuous, hence following two scenarios will need attention**\n",
        "1. Continuous Target Variable Vs Continuous Predictor\n",
        "2. Continuous Target Variable Vs Categorical Predictor\n",
        "\n"
      ],
      "metadata": {
        "id": "fEdMTBjn__Ds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relationship exploration: Continuous Vs Continuous -- Scatter Charts**\n",
        "\n",
        "* When the Target variable is continuous and the predictor is also continuous, we can visualize the relationship between the two variables using scatter plot and measure the strength of relation using a metric called pearson's correlation value.\n",
        "\n"
      ],
      "metadata": {
        "id": "B25xTMSSBahu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ContinuousCols=['age','bmi']\n",
        "\n",
        "# Plotting scatter chart for each predictor vs the target variable\n",
        "for predictor in ContinuousCols:\n",
        "   insurance_data.plot.scatter(x=predictor, y='charges', figsize=(10,5), title=predictor+\" VS \"+ 'charges')"
      ],
      "metadata": {
        "id": "ShqXE1ywBr-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scatter Charts Interpretation**\n",
        "\n",
        "1. Scatter charts help us see how two things relate to each other.\n",
        "2. Increasing Trend: When the points go up from left to right, it shows a positive relationship. This means when one thing increases, the other one tends to increase too. This is useful in machine learning because it can help predict future trends.\n",
        "3. Decreasing Trend: If the points go down from left to right, it shows a negative relationship. In this case, when one thing increases, the other decreases. This information is also useful for building machine learning models.\n",
        "4. No Trend: If the points don't show any clear pattern, it means there's no strong relationship between the two variables. This suggests that using this variable to predict something in machine learning might not work well.\n",
        "5. By looking at the scatter chart, we can understand if a variable might be helpful for predictions. To be more sure, we check the correlation value next.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Q2EgkBwDxZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 13: Statistical Feature Selection (Continuous Vs Continuous) using Correlation value**\n",
        "\n",
        "1. Pearson's correlation coefficient is a powerful metric for doing this.\n",
        "2. It can simply be calculated as the covariance between two features x and y (numerator) divided by the product of their standard deviations (denominator):\n",
        "\n",
        "![Screenshot 2024-04-28 010201.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "3. This value can be calculated only between two numeric columns. Correlation between [-1,0) means inversely proportional, the scatter plot will show a downward trend.\n",
        "4. Correlation between (0,1] means directly proportional, the scatter plot will show a upward trend.\n",
        "5. Correlation near {0} means No relationship, the scatter plot will show no clear trend.\n",
        "6. If Correlation value between two variables is > 0.5 in magnitude, it indicates good relationship the sign does not matter.\n",
        "7. We observe the correlations between Target variable and all other predictor variables(s) to check which columns/features/predictors are actually related to the target variable in question."
      ],
      "metadata": {
        "id": "-XpEEi3vGF7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating correlation matrix\n",
        "ContinuousCols=['age', 'charges', 'bmi',]"
      ],
      "metadata": {
        "id": "Opvi-H55G4cW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the correlation matrix\n",
        "CorrelationData=insurance_data[ContinuousCols].corr()\n",
        "CorrelationData"
      ],
      "metadata": {
        "id": "qfuUBP3vG7fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering only those columns where absolute correlation > 0.5 with Target Variable\n",
        "# reduce the 0.5 threshold if no variable is selected\n",
        "CorrelationData['charges'][abs(CorrelationData['charges']) > 0.5 ]"
      ],
      "metadata": {
        "id": "bOxsEH7JHAlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 13**\n",
        "\n",
        "1. Final selected Continuous columns:\n",
        "2. 'age'"
      ],
      "metadata": {
        "id": "POkdrJqWHHFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 14: Relationship exploration: Categorical Vs Continuous -- Box Plots**\n",
        "\n",
        "* When the target variable is Continuous and the predictor variable is Categorical we analyze the relation using Boxplots, and\n",
        "* Measure the strength of relation using Anova test.\n",
        "\n"
      ],
      "metadata": {
        "id": "RmacRUHYUEyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots for continuous Target Variable \"charges\" and Categorical predictors\n",
        "CategoricalColsList=['sex', 'children', 'smoker', 'region']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, PlotCanvas=plt.subplots(nrows=1, ncols=len(CategoricalColsList), figsize=(18,5))\n",
        "\n",
        "# Creating box plots for each continuous predictor against the Target Variable \"MEDV\"\n",
        "for PredictorCol , i in zip(CategoricalColsList, range(len(CategoricalColsList))):\n",
        "    insurance_data.boxplot(column='charges', by=PredictorCol, figsize=(5,5), vert=True, ax=PlotCanvas[i])"
      ],
      "metadata": {
        "id": "SfIdHWJAdhKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 14**\n",
        "\n",
        "1. These plots gives an idea about the data distribution of continuous predictor in the Y-axis for each of the category in the X-Axis.\n",
        "2. If the distribution looks similar for each category(Boxes are in the same line), that means the the continuous variable has NO effect on the target variable. Hence, the variables are not correlated to each other.\n",
        "3. On the other hand if the distribution is different for each category(the boxes are not in same line!). It hints that these variables might be correlated with MEDV.\n",
        "4. For this datadata, both the categorical predictors looks correlated with the Target variable.\n",
        "\n",
        "We confirm this by looking at the results of ANOVA test below.\n",
        "\n"
      ],
      "metadata": {
        "id": "7-SQQErreUn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 15: Statistical Feature Selection (Categorical Vs Continuous) using ANOVA test**\n",
        "\n",
        "1. Analysis of variance(ANOVA) is performed to check if there is any relationship between the given continuous and categorical variable.\n",
        "2. Assumption(H0) Null Hypothesis: There is NO relation between the given variables (i.e.\n",
        "3. The average(mean) values of the numeric Target variable is same for all the groups in the categorical Predictor variable).\n",
        "4. ANOVA Test result: Probability of H0 (Null Hypothesis being true.\n"
      ],
      "metadata": {
        "id": "ZjfuItJWlWK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to find the statistical relationship with all the categorical variables\n",
        "def FunctionAnova(inpData, TargetVariable, CategoricalPredictorList):\n",
        "    from scipy.stats import f_oneway\n",
        "\n",
        "    # Creating an empty list of final selected predictors\n",
        "    SelectedPredictors=[]\n",
        "\n",
        "    print('##### ANOVA Results ##### \\n')\n",
        "    for predictor in CategoricalPredictorList:\n",
        "        CategoryGroupLists=inpData.groupby(predictor)[TargetVariable].apply(list)\n",
        "        AnovaResults = f_oneway(*CategoryGroupLists)\n",
        "\n",
        "        # If the ANOVA P-Value is <0.05, that means we reject H0\n",
        "        if (AnovaResults[1] < 0.05):\n",
        "            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
        "            SelectedPredictors.append(predictor)\n",
        "        else:\n",
        "            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
        "\n",
        "    return(SelectedPredictors)"
      ],
      "metadata": {
        "id": "HGXLYvWooFVU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function to check which categorical variables are correlated with target\n",
        "CategoricalPredictorList=['sex', 'children', 'smoker', 'region']\n",
        "FunctionAnova(inpData=insurance_data,\n",
        "              TargetVariable='charges',\n",
        "              CategoricalPredictorList=CategoricalPredictorList)"
      ],
      "metadata": {
        "id": "6NoRl2fNrO3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from step 15**\n",
        "\n",
        "1. The results of ANOVA confirm our visual analysis using box plots above.\n",
        "2. All categorical variables are correlated with the Target variable except 'sex'.\n",
        "3. This is something we can guess by looking at the box plots!\n",
        "4. Final selected Categorical columns:\n",
        "\n",
        "'children', 'smoker', 'region'"
      ],
      "metadata": {
        "id": "1TWn06QRrWzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting final Predictors/Features for building Machine Learning/AI model**\n",
        "\n",
        "* Based on the extensive tests with exploratory data analysis, we can select the final features/predictors/columns for machine learning model building as:\n",
        "* 'age', 'children', 'smoker', 'region'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pLsXLZwXsJwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SelectedColumns=['age', 'children', 'smoker', 'region']\n",
        "\n",
        "# Selecting final columns\n",
        "DataForML=insurance_data[SelectedColumns]\n",
        "DataForML.head()"
      ],
      "metadata": {
        "id": "jgbShB_4swea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving this final data subset for reference during deployment\n",
        "DataForML.to_pickle('DataForML.pkl')"
      ],
      "metadata": {
        "id": "Wd85jRvKtBJJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 16: Data Pre-processing for Machine Learning Model Building or Model Development**\n",
        "1. List of steps that needs to be performed on predictor variables before data can be used for machine learning.\n",
        "2. Converting each Ordinal Categorical columns to numeric.\n",
        "3. Converting Binary nominal Categorical columns to numeric using 1/0 mapping.\n",
        "4. Converting all other nominal categorical columns to numeric using pd.get_dummies().\n",
        "5. Data Transformation (Optional): Standardization/Normalization/log/sqrt. Important if you are using distance based algorithms like KNN, or Neural Networks.\n",
        "6. Converting the ordinal variable to numeric - In this data there. is no Ordinal categorical variable.\n",
        "7. Converting the binary nominal variable to numeric using 1/0 mapping: There is no binary nominal variable in string format in this data.\n",
        "\n"
      ],
      "metadata": {
        "id": "vDWBymvsyWkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the nominal variable to numeric using get_dummies()**\n",
        "\n"
      ],
      "metadata": {
        "id": "oXeWHwAd4Off"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treating all the nominal variables at once using dummy variables\n",
        "DataForML_Numeric=pd.get_dummies(DataForML)\n",
        "\n",
        "# Adding Target Variable to the data\n",
        "DataForML_Numeric['charges']=insurance_data['charges']\n",
        "\n",
        "# Printing sample rows\n",
        "DataForML_Numeric.head()"
      ],
      "metadata": {
        "id": "BRm1y-Oa4UnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 17: Machine Learning Model Development:**\n",
        "\n",
        "1. Splitting the data into Training and Testing sample.\n",
        "2. We dont use the full data for creating the model (training data).\n",
        "3. Some data is randomly selected and kept aside for checking how good the model is.\n",
        "4. This is known as Testing Data and the remaining data is called Training data on which the model is built.\n",
        "5. Typically 70% of data is used as Training data and the rest 30% is used as Tesing data."
      ],
      "metadata": {
        "id": "28pZC7Qj4soW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing all the column names for our reference\n",
        "DataForML_Numeric.columns"
      ],
      "metadata": {
        "id": "Iyz7mVtqDFp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate Target Variable and Predictor Variables\n",
        "TargetVariable='charges'\n",
        "Predictors=['age', 'children', ]\n",
        "\n",
        "X=DataForML_Numeric[Predictors].values\n",
        "y=DataForML_Numeric[TargetVariable].values\n",
        "\n",
        "# Split the data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)"
      ],
      "metadata": {
        "id": "-7CYAHD_DKoQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 18: Standardization/Normalization of data**\n",
        "\n",
        "1. we can choose not to run this step if we want to compare the resultant accuracy of this transformation with the accuracy of raw data (Optional Step).\n",
        "2. However, if we are using KNN or Neural Networks, then this step becomes necessary."
      ],
      "metadata": {
        "id": "nQhFdWPJD5O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Sandardization of data ###\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "# Choose either standardization or Normalization\n",
        "# On this data Min Max Normalization produced better results\n",
        "\n",
        "# Choose between standardization and MinMAx normalization\n",
        "#PredictorScaler=StandardScaler()\n",
        "PredictorScaler=MinMaxScaler()\n",
        "\n",
        "# Storing the fit object for later reference\n",
        "PredictorScalerFit=PredictorScaler.fit(X)\n",
        "\n",
        "# Generating the standardized values of X\n",
        "X=PredictorScalerFit.transform(X)\n",
        "\n",
        "# Split the data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "p26WLn9uEiu6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check for the sampled data\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "65uxAxxhusp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 19: Multiple Linear Regression Algorithm For ML/AI model building**\n",
        "\n"
      ],
      "metadata": {
        "id": "9TMXWuU9u0tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiple Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "RegModel = LinearRegression()\n",
        "import numpy as np\n",
        "\n",
        "# Printing all the parameters of Linear regression\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "LREG=RegModel.fit(X_train,y_train)\n",
        "prediction=LREG.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults.head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "  TestingDataResults['charges']-TestingDataResults['Predictedcharges']))/TestingDataResults['charges'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "7nUUwzVNu91X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Regressor**"
      ],
      "metadata": {
        "id": "WxIT6-jhwbRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Trees (Multiple if-else statements!)\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "RegModel = DecisionTreeRegressor(max_depth=5,criterion='friedman_mse')\n",
        "# Good Range of Max_depth = 2 to 20\n",
        "\n",
        "# Printing all the parameters of Decision Tree\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "DT=RegModel.fit(X_train,y_train)\n",
        "prediction=DT.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))\n",
        "\n",
        "# Plotting the feature importance for Top 10 most important columns\n",
        "%matplotlib inline\n",
        "feature_importances = pd.Series(DT.feature_importances_, index=Predictors)\n",
        "feature_importances.nlargest(10).plot(kind='barh')\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults.head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "    TestingDataResults['charges']-TestingDataResults['Predictedcharges']))/TestingDataResults['charges'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "fE5VFYl1wgHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting/Visualising the Decision Tree**"
      ],
      "metadata": {
        "id": "Up1OxHwHxJZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from IPython.display import Image\n",
        "from sklearn import tree\n",
        "import pydotplus\n",
        "\n",
        "# Create DOT data\n",
        "dot_data = tree.export_graphviz(RegModel, out_file=None,\n",
        "                                feature_names=Predictors, class_names=TargetVariable)\n",
        "\n",
        "# printing the rules\n",
        "#print(dot_data)\n",
        "\n",
        "# Draw graph\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "# Show graph\n",
        "Image(graph.create_png(), width=1600,height=1000)\n",
        "# Double click on the graph to zoom in"
      ],
      "metadata": {
        "id": "us7kAA1PxNnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Regressor**"
      ],
      "metadata": {
        "id": "Y7AuiukOxUmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest (Bagging of multiple Decision Trees)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "RegModel = RandomForestRegressor(max_depth=4, n_estimators=400,criterion='friedman_mse')\n",
        "# Good range for max_depth: 2-10 and n_estimators: 100-1000\n",
        "\n",
        "# Printing all the parameters of Random Forest\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "RF=RegModel.fit(X_train,y_train)\n",
        "prediction=RF.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, RF.predict(X_train)))\n",
        "\n",
        "# Plotting the feature importance for Top 10 most important columns\n",
        "%matplotlib inline\n",
        "feature_importances = pd.Series(RF.feature_importances_, index=Predictors)\n",
        "feature_importances.nlargest(10).plot(kind='barh')\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults.head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "    TestingDataResults['charges']-TestingDataResults['Predictedcharges']))/TestingDataResults['charges'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "o5arWQ7cxZaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting One of the Decision Tree in Random Forest Regressor**"
      ],
      "metadata": {
        "id": "syt99iY6xl8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a single Decision Tree from Random Forest\n",
        "# Load libraries\n",
        "from IPython.display import Image\n",
        "from sklearn import tree\n",
        "import pydotplus\n",
        "\n",
        "# Create DOT data for the 6th Decision Tree in Random Forest\n",
        "dot_data = tree.export_graphviz(RegModel.estimators_[5] , out_file=None, feature_names=Predictors, class_names=TargetVariable)\n",
        "\n",
        "# Draw graph\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "# Show graph\n",
        "Image(graph.create_png(), width=1600,height=1000)\n",
        "# Double click on the graph to zoom in"
      ],
      "metadata": {
        "id": "eNwuFWcVxsfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 20: AdaBoost Algorithm For ML/AI model building**"
      ],
      "metadata": {
        "id": "dPkWhspBxx0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaboost (Boosting of multiple Decision Trees)\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Choosing Decision Tree with 6 level as the weak learner\n",
        "DTR=DecisionTreeRegressor(max_depth=3)\n",
        "RegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=0.04)\n",
        "\n",
        "# Printing all the parameters of Adaboost\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "AB=RegModel.fit(X_train,y_train)\n",
        "prediction=AB.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, AB.predict(X_train)))\n",
        "\n",
        "# Plotting the feature importance for Top 10 most important columns\n",
        "%matplotlib inline\n",
        "feature_importances = pd.Series(AB.feature_importances_, index=Predictors)\n",
        "feature_importances.nlargest(10).plot(kind='barh')\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults.head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "  TestingDataResults['charges']-TestingDataResults['Predictedcharges']))/TestingDataResults['charges'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "vc58yfRdx_rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost Regressor**"
      ],
      "metadata": {
        "id": "XJGM060syKIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##XGBoost\n",
        "# Xtreme Gradient Boosting (XGBoost)\n",
        "from xgboost import XGBRegressor\n",
        "RegModel=XGBRegressor(max_depth=2,\n",
        "                      learning_rate=0.1,\n",
        "                      n_estimators=1000,\n",
        "                      objective='reg:linear',\n",
        "                      booster='gbtree')\n",
        "\n",
        "# Printing all the parameters of XGBoost\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "XGB=RegModel.fit(X_train,y_train)\n",
        "prediction=XGB.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))\n",
        "\n",
        "# Plotting the feature importance for Top 10 most important columns\n",
        "%matplotlib inline\n",
        "feature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\n",
        "feature_importances.nlargest(10).plot(kind='barh')\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults.head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        " TestingDataResults['charges']-TestingDataResults['Predictedcharges']))/TestingDataResults['charges'])\n",
        "\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "dwMWxehCyRa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting a single Decision tree out of XGBoost**"
      ],
      "metadata": {
        "id": "51Vstsd7ycp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting a single Decision tree out of XGBoost\n",
        "from xgboost import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(20, 8))\n",
        "plot_tree(XGB, num_trees=10, ax=ax)"
      ],
      "metadata": {
        "id": "e02aC5zYyjYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Nearest Neighbor(KNN)**"
      ],
      "metadata": {
        "id": "gWDyc6mFyqV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#kNN\n",
        "# K-Nearest Neighbor(KNN)\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "RegModel = KNeighborsRegressor(n_neighbors=3)\n",
        "\n",
        "# Printing all the parameters of KNN\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "KNN=RegModel.fit(X_train,y_train)\n",
        "prediction=KNN.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))\n",
        "\n",
        "# Plotting the feature importance for Top 10 most important columns\n",
        "# The variable importance chart is not available for KNN\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults.head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "  TestingDataResults['charges']-TestingDataResults['Predictedcharges']))/TestingDataResults['charges'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "LmIARLEZyvZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine (SVM) Regressor**"
      ],
      "metadata": {
        "id": "DZif0mOqy2qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machines(SVM)\n",
        "from sklearn import svm\n",
        "RegModel = svm.SVR(C=50, kernel='rbf', gamma=0.01)\n",
        "\n",
        "# Printing all the parameters\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "SVM=RegModel.fit(X_train,y_train)\n",
        "prediction=SVM.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, SVM.predict(X_train)))\n",
        "\n",
        "# Plotting the feature importance for Top 10 most important columns\n",
        "# The built in attribute SVM.coef_ works only for linear kernel\n",
        "%matplotlib inline\n",
        "#feature_importances = pd.Series(SVM.coef_[0], index=Predictors)\n",
        "#feature_importances.nlargest(10).plot(kind='barh')\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults.head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "  TestingDataResults['charges']-TestingDataResults['Predictedcharges']))/TestingDataResults['charges'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "iMnh4dFQy9kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 21: Model Deployment**\n",
        "\n",
        "1. Deployment of the Model - Based on the above trials we select that algorithm which produces the best average accuracy.\n",
        "2. In this case, multiple algorithms have produced similar kind of average accuracy. Hence, we can choose any one of them.\n",
        "3. I am choosing XGboost as the final model it has the highest accuracy!\n",
        "4. In order to deploy the model we follow steps outlined next.\n",
        "5. Train/Build the model again using 100% data available.\n",
        "6. Save the model as a serialized file which can be stored anywhere.\n",
        "7. Create a python function which gets integrated with front-end Viewer(GUI/ Website etc.) to take all the inputs and returns the prediction.\n",
        "8. Choosing only the most important variables\n",
        "9. Its beneficial to keep lesser number of predictors for the model while deploying it in production.\n",
        "10. The lesser predictors you keep, the better it is, because the model will be less dependent on predictor columns/features, hence, more stable.\n",
        "11. This is especially crucial when there are many different predictor columns or features in the data.\n",
        "12. For this dataset, 'age' and 'children' are the most important predictors. They consistently rank highest in importance across all algorithms used. Therefore, using these variables as the primary predictors will likely improve the accuracy of the house price prediction system.\n"
      ],
      "metadata": {
        "id": "UIgcNqhOzFbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate Target Variable and Predictor Variables\n",
        "TargetVariable='charges'\n",
        "\n",
        "# Selecting the final set of predictors for the deployment\n",
        "# Based on the variable importance charts of multiple algorithms above\n",
        "Predictors=['age', 'children']\n",
        "\n",
        "X=DataForML_Numeric[Predictors].values\n",
        "y=DataForML_Numeric[TargetVariable].values\n",
        "\n",
        "### Sandardization of data ###\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "# Choose either standardization or Normalization\n",
        "# On this data Min Max Normalization produced better results\n",
        "\n",
        "# Choose between standardization and MinMAx normalization\n",
        "#PredictorScaler=StandardScaler()\n",
        "PredictorScaler=MinMaxScaler()\n",
        "\n",
        "# Storing the fit object for later reference\n",
        "PredictorScalerFit=PredictorScaler.fit(X)\n",
        "\n",
        "# Generating the standardized values of X\n",
        "X=PredictorScalerFit.transform(X)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "CY0HYC8q_KqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross validating the final model accuracy with less predictors**"
      ],
      "metadata": {
        "id": "MjYGrZlu_WMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# choose from different tunable hyper parameters\n",
        "from xgboost import XGBRegressor\n",
        "RegModel=XGBRegressor(max_depth=6,\n",
        "                      learning_rate=0.7,\n",
        "                      n_estimators=1000,\n",
        "                      objective='reg:linear',\n",
        "                      booster='gbtree')\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "metadata": {
        "id": "3peGKwoU_kz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retraining the final model using 100% data**"
      ],
      "metadata": {
        "id": "D3w5QWRW_0OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 100% Data available\n",
        "Final_XGB_Model=RegModel.fit(X,y)"
      ],
      "metadata": {
        "id": "lX2Jk9-5_4OI"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model as a serialized file which can be stored anywhere**"
      ],
      "metadata": {
        "id": "OhH6BuerAFLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Saving the Python objects as serialized files can be done using pickle library\n",
        "# Here let us save the Final model\n",
        "with open('Final_XGB_Model.pkl', 'wb') as fileWriteStream:\n",
        "    pickle.dump(Final_XGB_Model, fileWriteStream)\n",
        "    # Don't forget to close the filestream!\n",
        "    fileWriteStream.close()\n",
        "\n",
        "print('pickle file of Predictive Model is saved at Location:',os.getcwd())"
      ],
      "metadata": {
        "id": "Wy2nGQyJANUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a python function**"
      ],
      "metadata": {
        "id": "CAjIt7iRAWcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import IGNORECASE\n",
        "# This Function can be called from any from any front end tool/website\n",
        "\n",
        "def FunctionPredictResult(InputData):\n",
        "    import pandas as pd\n",
        "    Num_Inputs=InputData.shape[0]\n",
        "\n",
        "    # Making sure the input data has same columns as it was used for training the model\n",
        "    # Also, if standardization/normalization was done, then same must be done for new input\n",
        "\n",
        "    # Appending the new data with the Training data\n",
        "    DataForML=pd.read_pickle('DataForML.pkl')\n",
        "    #InputData=InputData.append(DataForML, ignore_index=True)\n",
        "    InputData = pd.concat([InputData, DataForML], ignore_index=True)\n",
        "\n",
        "    # Generating dummy variables for rest of the nominal variables\n",
        "    InputData=pd.get_dummies(InputData)\n",
        "\n",
        "    # Maintaining the same order of columns as it was during the model training\n",
        "    Predictors=['age', 'children']\n",
        "\n",
        "    # Generating the input values to the model\n",
        "    X=InputData[Predictors].values[0:Num_Inputs]\n",
        "\n",
        "    # Generating the standardized values of X since it was done while model training also\n",
        "    X=PredictorScalerFit.transform(X)\n",
        "\n",
        "    # Loading the Function from pickle file\n",
        "    import pickle\n",
        "    with open('Final_XGB_Model.pkl', 'rb') as fileReadStream:\n",
        "        PredictionModel=pickle.load(fileReadStream)\n",
        "        # Don't forget to close the filestream!\n",
        "        fileReadStream.close()\n",
        "\n",
        "    # Genrating Predictions\n",
        "    Prediction=PredictionModel.predict(X)\n",
        "    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])\n",
        "    return(PredictionResult)"
      ],
      "metadata": {
        "id": "r4bfqi3zAeL8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calling the function for some new data**"
      ],
      "metadata": {
        "id": "j2f2bcbMAlxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the function for prediction\n",
        "def FunctionPredictResult(InputData):\n",
        "    # Load necessary libraries and models\n",
        "    with open('Final_XGB_Model.pkl', 'rb') as fileReadStream:\n",
        "        PredictionModel = pickle.load(fileReadStream)\n",
        "\n",
        "    # Load the data used for model training\n",
        "    DataForML = pd.read_pickle('DataForML.pkl')\n",
        "\n",
        "    # Combine the new input data with the training data\n",
        "    InputData = pd.concat([InputData, DataForML], ignore_index=True)\n",
        "\n",
        "    # Ensure that the input data has the same columns as it was used for training\n",
        "    Predictors = ['age', 'children']\n",
        "\n",
        "    # Extract the relevant features and generate dummy variables if necessary\n",
        "    InputData = InputData[Predictors]\n",
        "\n",
        "    # If there are nominal variables requiring dummy encoding, you can apply pd.get_dummies here\n",
        "\n",
        "    # Assuming PredictorScalerFit is defined elsewhere and used for standardization\n",
        "    # X = PredictorScalerFit.transform(InputData)\n",
        "\n",
        "    # Generate predictions\n",
        "    Predictions = PredictionModel.predict(InputData)\n",
        "\n",
        "    # Create a DataFrame to store the predictions\n",
        "    PredictionResult = pd.DataFrame(Predictions, columns=['Prediction'])\n",
        "\n",
        "    return PredictionResult\n",
        "\n",
        "# Define the new sample data\n",
        "NewSampleData = pd.DataFrame(data=[[21, 0], [28, 3]], columns=['age', 'children'])\n",
        "\n",
        "# Call the function to predict on the new data\n",
        "prediction_result = FunctionPredictResult(NewSampleData)\n",
        "\n",
        "# Print the prediction result\n",
        "print(prediction_result)\n"
      ],
      "metadata": {
        "id": "bJ-ZT-tl0BRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "1. The FunctionPredictResult() is designed to make predictions for one or multiple new cases at once.\n",
        "2. Therefore, you can set it up to run automatically every night through a batch job or cron job, to handle all the house price predictions needed in the system.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9ZzrlvjQA66T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploying a predictive model as an API**\n",
        "\n",
        "1. Django and Flask are common tools for setting up predictive models on a web service.\n",
        "2. You can access your predictive models through a web address from any interface, such as Tableau, Java, or AngularJS.\n"
      ],
      "metadata": {
        "id": "Djmp0msfBSD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploying the model with few parameters**\n",
        "\n",
        "**Function for predictions API**"
      ],
      "metadata": {
        "id": "AA38Rc7_BY5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Define the function for prediction\n",
        "def FunctionPredictResult(InputData):\n",
        "    # Load necessary libraries and models\n",
        "    with open('Final_XGB_Model.pkl', 'rb') as fileReadStream:\n",
        "        PredictionModel = pickle.load(fileReadStream)\n",
        "\n",
        "    # Load the data used for model training\n",
        "    DataForML = pd.read_pickle('DataForML.pkl')\n",
        "\n",
        "    # Combine the new input data with the training data\n",
        "    InputData = pd.concat([InputData, DataForML], ignore_index=True)\n",
        "\n",
        "    # Ensure that the input data has the same columns as it was used for training\n",
        "    Predictors = ['age', 'children']\n",
        "\n",
        "    # Extract the relevant features and generate dummy variables if necessary\n",
        "    InputData = InputData[Predictors]\n",
        "\n",
        "    # If there are nominal variables requiring dummy encoding, you can apply pd.get_dummies here\n",
        "\n",
        "    # Assuming PredictorScalerFit is defined elsewhere and used for standardization\n",
        "    # X = PredictorScalerFit.transform(InputData)\n",
        "\n",
        "    # Generate predictions\n",
        "    Predictions = PredictionModel.predict(InputData)\n",
        "\n",
        "    # Create a DataFrame to store the predictions\n",
        "    PredictionResult = pd.DataFrame(Predictions, columns=['Prediction'])\n",
        "\n",
        "    return PredictionResult\n",
        "\n",
        "# Creating the function which can take inputs and return prediction\n",
        "def FunctionGeneratePrediction(inp_age, inp_children):\n",
        "    # Creating a DataFrame for the model input\n",
        "    SampleInputData = pd.DataFrame(data=[[inp_age, inp_children]], columns=['age', 'children'])\n",
        "\n",
        "    # Calling the function defined above using the input parameters\n",
        "    Predictions = FunctionPredictResult(InputData=SampleInputData)\n",
        "\n",
        "    # Returning the predictions\n",
        "    return Predictions.to_json()\n",
        "\n",
        "# Function call\n",
        "result = FunctionGeneratePrediction(inp_age=21, inp_children=0)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "oioKPcn0Bj7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8febe62a-e9a2-4bb0-afa2-5bc8be23e92f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"Prediction\":{\"0\":6496.8862304688,\"1\":6496.8862304688,\"2\":6496.8862304688,\"3\":6496.8862304688,\"4\":6496.8862304688,\"5\":6496.8862304688,\"6\":6496.8862304688,\"7\":6496.8862304688,\"8\":6496.8862304688,\"9\":6496.8862304688,\"10\":6496.8862304688,\"11\":6496.8862304688,\"12\":6496.8862304688,\"13\":6496.8862304688,\"14\":6496.8862304688,\"15\":6496.8862304688,\"16\":6496.8862304688,\"17\":6496.8862304688,\"18\":6496.8862304688,\"19\":6496.8862304688,\"20\":6496.8862304688,\"21\":6496.8862304688,\"22\":6496.8862304688,\"23\":6496.8862304688,\"24\":6496.8862304688,\"25\":6496.8862304688,\"26\":6496.8862304688,\"27\":6496.8862304688,\"28\":6496.8862304688,\"29\":6496.8862304688,\"30\":6496.8862304688,\"31\":6496.8862304688,\"32\":6496.8862304688,\"33\":6496.8862304688,\"34\":6496.8862304688,\"35\":6496.8862304688,\"36\":6496.8862304688,\"37\":6496.8862304688,\"38\":6496.8862304688,\"39\":6496.8862304688,\"40\":6496.8862304688,\"41\":6496.8862304688,\"42\":6496.8862304688,\"43\":6496.8862304688,\"44\":6496.8862304688,\"45\":6496.8862304688,\"46\":6496.8862304688,\"47\":6496.8862304688,\"48\":6496.8862304688,\"49\":6496.8862304688,\"50\":6496.8862304688,\"51\":6496.8862304688,\"52\":6496.8862304688,\"53\":6496.8862304688,\"54\":6496.8862304688,\"55\":6496.8862304688,\"56\":6496.8862304688,\"57\":6496.8862304688,\"58\":6496.8862304688,\"59\":6496.8862304688,\"60\":6496.8862304688,\"61\":6496.8862304688,\"62\":6496.8862304688,\"63\":6496.8862304688,\"64\":6496.8862304688,\"65\":6496.8862304688,\"66\":6496.8862304688,\"67\":6496.8862304688,\"68\":6496.8862304688,\"69\":6496.8862304688,\"70\":6496.8862304688,\"71\":6496.8862304688,\"72\":6496.8862304688,\"73\":6496.8862304688,\"74\":6496.8862304688,\"75\":6496.8862304688,\"76\":6496.8862304688,\"77\":6496.8862304688,\"78\":6496.8862304688,\"79\":6496.8862304688,\"80\":6496.8862304688,\"81\":6496.8862304688,\"82\":6496.8862304688,\"83\":6496.8862304688,\"84\":6496.8862304688,\"85\":6496.8862304688,\"86\":6496.8862304688,\"87\":6496.8862304688,\"88\":6496.8862304688,\"89\":6496.8862304688,\"90\":6496.8862304688,\"91\":6496.8862304688,\"92\":6496.8862304688,\"93\":6496.8862304688,\"94\":6496.8862304688,\"95\":6496.8862304688,\"96\":6496.8862304688,\"97\":6496.8862304688,\"98\":6496.8862304688,\"99\":6496.8862304688,\"100\":6496.8862304688,\"101\":6496.8862304688,\"102\":6496.8862304688,\"103\":6496.8862304688,\"104\":6496.8862304688,\"105\":6496.8862304688,\"106\":6496.8862304688,\"107\":6496.8862304688,\"108\":6496.8862304688,\"109\":6496.8862304688,\"110\":6496.8862304688,\"111\":6496.8862304688,\"112\":6496.8862304688,\"113\":6496.8862304688,\"114\":6496.8862304688,\"115\":6496.8862304688,\"116\":6496.8862304688,\"117\":6496.8862304688,\"118\":6496.8862304688,\"119\":6496.8862304688,\"120\":6496.8862304688,\"121\":6496.8862304688,\"122\":6496.8862304688,\"123\":6496.8862304688,\"124\":6496.8862304688,\"125\":6496.8862304688,\"126\":6496.8862304688,\"127\":6496.8862304688,\"128\":6496.8862304688,\"129\":6496.8862304688,\"130\":6496.8862304688,\"131\":6496.8862304688,\"132\":6496.8862304688,\"133\":6496.8862304688,\"134\":6496.8862304688,\"135\":6496.8862304688,\"136\":6496.8862304688,\"137\":6496.8862304688,\"138\":6496.8862304688,\"139\":6496.8862304688,\"140\":6496.8862304688,\"141\":6496.8862304688,\"142\":6496.8862304688,\"143\":6496.8862304688,\"144\":6496.8862304688,\"145\":6496.8862304688,\"146\":6496.8862304688,\"147\":6496.8862304688,\"148\":6496.8862304688,\"149\":6496.8862304688,\"150\":6496.8862304688,\"151\":6496.8862304688,\"152\":6496.8862304688,\"153\":6496.8862304688,\"154\":6496.8862304688,\"155\":6496.8862304688,\"156\":6496.8862304688,\"157\":6496.8862304688,\"158\":6496.8862304688,\"159\":6496.8862304688,\"160\":6496.8862304688,\"161\":6496.8862304688,\"162\":6496.8862304688,\"163\":6496.8862304688,\"164\":6496.8862304688,\"165\":6496.8862304688,\"166\":6496.8862304688,\"167\":6496.8862304688,\"168\":6496.8862304688,\"169\":6496.8862304688,\"170\":6496.8862304688,\"171\":6496.8862304688,\"172\":6496.8862304688,\"173\":6496.8862304688,\"174\":6496.8862304688,\"175\":6496.8862304688,\"176\":6496.8862304688,\"177\":6496.8862304688,\"178\":6496.8862304688,\"179\":6496.8862304688,\"180\":6496.8862304688,\"181\":6496.8862304688,\"182\":6496.8862304688,\"183\":6496.8862304688,\"184\":6496.8862304688,\"185\":6496.8862304688,\"186\":6496.8862304688,\"187\":6496.8862304688,\"188\":6496.8862304688,\"189\":6496.8862304688,\"190\":6496.8862304688,\"191\":6496.8862304688,\"192\":6496.8862304688,\"193\":6496.8862304688,\"194\":6496.8862304688,\"195\":6496.8862304688,\"196\":6496.8862304688,\"197\":6496.8862304688,\"198\":6496.8862304688,\"199\":6496.8862304688,\"200\":6496.8862304688,\"201\":6496.8862304688,\"202\":6496.8862304688,\"203\":6496.8862304688,\"204\":6496.8862304688,\"205\":6496.8862304688,\"206\":6496.8862304688,\"207\":6496.8862304688,\"208\":6496.8862304688,\"209\":6496.8862304688,\"210\":6496.8862304688,\"211\":6496.8862304688,\"212\":6496.8862304688,\"213\":6496.8862304688,\"214\":6496.8862304688,\"215\":6496.8862304688,\"216\":6496.8862304688,\"217\":6496.8862304688,\"218\":6496.8862304688,\"219\":6496.8862304688,\"220\":6496.8862304688,\"221\":6496.8862304688,\"222\":6496.8862304688,\"223\":6496.8862304688,\"224\":6496.8862304688,\"225\":6496.8862304688,\"226\":6496.8862304688,\"227\":6496.8862304688,\"228\":6496.8862304688,\"229\":6496.8862304688,\"230\":6496.8862304688,\"231\":6496.8862304688,\"232\":6496.8862304688,\"233\":6496.8862304688,\"234\":6496.8862304688,\"235\":6496.8862304688,\"236\":6496.8862304688,\"237\":6496.8862304688,\"238\":6496.8862304688,\"239\":6496.8862304688,\"240\":6496.8862304688,\"241\":6496.8862304688,\"242\":6496.8862304688,\"243\":6496.8862304688,\"244\":6496.8862304688,\"245\":6496.8862304688,\"246\":6496.8862304688,\"247\":6496.8862304688,\"248\":6496.8862304688,\"249\":6496.8862304688,\"250\":6496.8862304688,\"251\":6496.8862304688,\"252\":6496.8862304688,\"253\":6496.8862304688,\"254\":6496.8862304688,\"255\":6496.8862304688,\"256\":6496.8862304688,\"257\":6496.8862304688,\"258\":6496.8862304688,\"259\":6496.8862304688,\"260\":6496.8862304688,\"261\":6496.8862304688,\"262\":6496.8862304688,\"263\":6496.8862304688,\"264\":6496.8862304688,\"265\":6496.8862304688,\"266\":6496.8862304688,\"267\":6496.8862304688,\"268\":6496.8862304688,\"269\":6496.8862304688,\"270\":6496.8862304688,\"271\":6496.8862304688,\"272\":6496.8862304688,\"273\":6496.8862304688,\"274\":6496.8862304688,\"275\":6496.8862304688,\"276\":6496.8862304688,\"277\":6496.8862304688,\"278\":6496.8862304688,\"279\":6496.8862304688,\"280\":6496.8862304688,\"281\":6496.8862304688,\"282\":6496.8862304688,\"283\":6496.8862304688,\"284\":6496.8862304688,\"285\":6496.8862304688,\"286\":6496.8862304688,\"287\":6496.8862304688,\"288\":6496.8862304688,\"289\":6496.8862304688,\"290\":6496.8862304688,\"291\":6496.8862304688,\"292\":6496.8862304688,\"293\":6496.8862304688,\"294\":6496.8862304688,\"295\":6496.8862304688,\"296\":6496.8862304688,\"297\":6496.8862304688,\"298\":6496.8862304688,\"299\":6496.8862304688,\"300\":6496.8862304688,\"301\":6496.8862304688,\"302\":6496.8862304688,\"303\":6496.8862304688,\"304\":6496.8862304688,\"305\":6496.8862304688,\"306\":6496.8862304688,\"307\":6496.8862304688,\"308\":6496.8862304688,\"309\":6496.8862304688,\"310\":6496.8862304688,\"311\":6496.8862304688,\"312\":6496.8862304688,\"313\":6496.8862304688,\"314\":6496.8862304688,\"315\":6496.8862304688,\"316\":6496.8862304688,\"317\":6496.8862304688,\"318\":6496.8862304688,\"319\":6496.8862304688,\"320\":6496.8862304688,\"321\":6496.8862304688,\"322\":6496.8862304688,\"323\":6496.8862304688,\"324\":6496.8862304688,\"325\":6496.8862304688,\"326\":6496.8862304688,\"327\":6496.8862304688,\"328\":6496.8862304688,\"329\":6496.8862304688,\"330\":6496.8862304688,\"331\":6496.8862304688,\"332\":6496.8862304688,\"333\":6496.8862304688,\"334\":6496.8862304688,\"335\":6496.8862304688,\"336\":6496.8862304688,\"337\":6496.8862304688,\"338\":6496.8862304688,\"339\":6496.8862304688,\"340\":6496.8862304688,\"341\":6496.8862304688,\"342\":6496.8862304688,\"343\":6496.8862304688,\"344\":6496.8862304688,\"345\":6496.8862304688,\"346\":6496.8862304688,\"347\":6496.8862304688,\"348\":6496.8862304688,\"349\":6496.8862304688,\"350\":6496.8862304688,\"351\":6496.8862304688,\"352\":6496.8862304688,\"353\":6496.8862304688,\"354\":6496.8862304688,\"355\":6496.8862304688,\"356\":6496.8862304688,\"357\":6496.8862304688,\"358\":6496.8862304688,\"359\":6496.8862304688,\"360\":6496.8862304688,\"361\":6496.8862304688,\"362\":6496.8862304688,\"363\":6496.8862304688,\"364\":6496.8862304688,\"365\":6496.8862304688,\"366\":6496.8862304688,\"367\":6496.8862304688,\"368\":6496.8862304688,\"369\":6496.8862304688,\"370\":6496.8862304688,\"371\":6496.8862304688,\"372\":6496.8862304688,\"373\":6496.8862304688,\"374\":6496.8862304688,\"375\":6496.8862304688,\"376\":6496.8862304688,\"377\":6496.8862304688,\"378\":6496.8862304688,\"379\":6496.8862304688,\"380\":6496.8862304688,\"381\":6496.8862304688,\"382\":6496.8862304688,\"383\":6496.8862304688,\"384\":6496.8862304688,\"385\":6496.8862304688,\"386\":6496.8862304688,\"387\":6496.8862304688,\"388\":6496.8862304688,\"389\":6496.8862304688,\"390\":6496.8862304688,\"391\":6496.8862304688,\"392\":6496.8862304688,\"393\":6496.8862304688,\"394\":6496.8862304688,\"395\":6496.8862304688,\"396\":6496.8862304688,\"397\":6496.8862304688,\"398\":6496.8862304688,\"399\":6496.8862304688,\"400\":6496.8862304688,\"401\":6496.8862304688,\"402\":6496.8862304688,\"403\":6496.8862304688,\"404\":6496.8862304688,\"405\":6496.8862304688,\"406\":6496.8862304688,\"407\":6496.8862304688,\"408\":6496.8862304688,\"409\":6496.8862304688,\"410\":6496.8862304688,\"411\":6496.8862304688,\"412\":6496.8862304688,\"413\":6496.8862304688,\"414\":6496.8862304688,\"415\":6496.8862304688,\"416\":6496.8862304688,\"417\":6496.8862304688,\"418\":6496.8862304688,\"419\":6496.8862304688,\"420\":6496.8862304688,\"421\":6496.8862304688,\"422\":6496.8862304688,\"423\":6496.8862304688,\"424\":6496.8862304688,\"425\":6496.8862304688,\"426\":6496.8862304688,\"427\":6496.8862304688,\"428\":6496.8862304688,\"429\":6496.8862304688,\"430\":6496.8862304688,\"431\":6496.8862304688,\"432\":6496.8862304688,\"433\":6496.8862304688,\"434\":6496.8862304688,\"435\":6496.8862304688,\"436\":6496.8862304688,\"437\":6496.8862304688,\"438\":6496.8862304688,\"439\":6496.8862304688,\"440\":6496.8862304688,\"441\":6496.8862304688,\"442\":6496.8862304688,\"443\":6496.8862304688,\"444\":6496.8862304688,\"445\":6496.8862304688,\"446\":6496.8862304688,\"447\":6496.8862304688,\"448\":6496.8862304688,\"449\":6496.8862304688,\"450\":6496.8862304688,\"451\":6496.8862304688,\"452\":6496.8862304688,\"453\":6496.8862304688,\"454\":6496.8862304688,\"455\":6496.8862304688,\"456\":6496.8862304688,\"457\":6496.8862304688,\"458\":6496.8862304688,\"459\":6496.8862304688,\"460\":6496.8862304688,\"461\":6496.8862304688,\"462\":6496.8862304688,\"463\":6496.8862304688,\"464\":6496.8862304688,\"465\":6496.8862304688,\"466\":6496.8862304688,\"467\":6496.8862304688,\"468\":6496.8862304688,\"469\":6496.8862304688,\"470\":6496.8862304688,\"471\":6496.8862304688,\"472\":6496.8862304688,\"473\":6496.8862304688,\"474\":6496.8862304688,\"475\":6496.8862304688,\"476\":6496.8862304688,\"477\":6496.8862304688,\"478\":6496.8862304688,\"479\":6496.8862304688,\"480\":6496.8862304688,\"481\":6496.8862304688,\"482\":6496.8862304688,\"483\":6496.8862304688,\"484\":6496.8862304688,\"485\":6496.8862304688,\"486\":6496.8862304688,\"487\":6496.8862304688,\"488\":6496.8862304688,\"489\":6496.8862304688,\"490\":6496.8862304688,\"491\":6496.8862304688,\"492\":6496.8862304688,\"493\":6496.8862304688,\"494\":6496.8862304688,\"495\":6496.8862304688,\"496\":6496.8862304688,\"497\":6496.8862304688,\"498\":6496.8862304688,\"499\":6496.8862304688,\"500\":6496.8862304688,\"501\":6496.8862304688,\"502\":6496.8862304688,\"503\":6496.8862304688,\"504\":6496.8862304688,\"505\":6496.8862304688,\"506\":6496.8862304688,\"507\":6496.8862304688,\"508\":6496.8862304688,\"509\":6496.8862304688,\"510\":6496.8862304688,\"511\":6496.8862304688,\"512\":6496.8862304688,\"513\":6496.8862304688,\"514\":6496.8862304688,\"515\":6496.8862304688,\"516\":6496.8862304688,\"517\":6496.8862304688,\"518\":6496.8862304688,\"519\":6496.8862304688,\"520\":6496.8862304688,\"521\":6496.8862304688,\"522\":6496.8862304688,\"523\":6496.8862304688,\"524\":6496.8862304688,\"525\":6496.8862304688,\"526\":6496.8862304688,\"527\":6496.8862304688,\"528\":6496.8862304688,\"529\":6496.8862304688,\"530\":6496.8862304688,\"531\":6496.8862304688,\"532\":6496.8862304688,\"533\":6496.8862304688,\"534\":6496.8862304688,\"535\":6496.8862304688,\"536\":6496.8862304688,\"537\":6496.8862304688,\"538\":6496.8862304688,\"539\":6496.8862304688,\"540\":6496.8862304688,\"541\":6496.8862304688,\"542\":6496.8862304688,\"543\":6496.8862304688,\"544\":6496.8862304688,\"545\":6496.8862304688,\"546\":6496.8862304688,\"547\":6496.8862304688,\"548\":6496.8862304688,\"549\":6496.8862304688,\"550\":6496.8862304688,\"551\":6496.8862304688,\"552\":6496.8862304688,\"553\":6496.8862304688,\"554\":6496.8862304688,\"555\":6496.8862304688,\"556\":6496.8862304688,\"557\":6496.8862304688,\"558\":6496.8862304688,\"559\":6496.8862304688,\"560\":6496.8862304688,\"561\":6496.8862304688,\"562\":6496.8862304688,\"563\":6496.8862304688,\"564\":6496.8862304688,\"565\":6496.8862304688,\"566\":6496.8862304688,\"567\":6496.8862304688,\"568\":6496.8862304688,\"569\":6496.8862304688,\"570\":6496.8862304688,\"571\":6496.8862304688,\"572\":6496.8862304688,\"573\":6496.8862304688,\"574\":6496.8862304688,\"575\":6496.8862304688,\"576\":6496.8862304688,\"577\":6496.8862304688,\"578\":6496.8862304688,\"579\":6496.8862304688,\"580\":6496.8862304688,\"581\":6496.8862304688,\"582\":6496.8862304688,\"583\":6496.8862304688,\"584\":6496.8862304688,\"585\":6496.8862304688,\"586\":6496.8862304688,\"587\":6496.8862304688,\"588\":6496.8862304688,\"589\":6496.8862304688,\"590\":6496.8862304688,\"591\":6496.8862304688,\"592\":6496.8862304688,\"593\":6496.8862304688,\"594\":6496.8862304688,\"595\":6496.8862304688,\"596\":6496.8862304688,\"597\":6496.8862304688,\"598\":6496.8862304688,\"599\":6496.8862304688,\"600\":6496.8862304688,\"601\":6496.8862304688,\"602\":6496.8862304688,\"603\":6496.8862304688,\"604\":6496.8862304688,\"605\":6496.8862304688,\"606\":6496.8862304688,\"607\":6496.8862304688,\"608\":6496.8862304688,\"609\":6496.8862304688,\"610\":6496.8862304688,\"611\":6496.8862304688,\"612\":6496.8862304688,\"613\":6496.8862304688,\"614\":6496.8862304688,\"615\":6496.8862304688,\"616\":6496.8862304688,\"617\":6496.8862304688,\"618\":6496.8862304688,\"619\":6496.8862304688,\"620\":6496.8862304688,\"621\":6496.8862304688,\"622\":6496.8862304688,\"623\":6496.8862304688,\"624\":6496.8862304688,\"625\":6496.8862304688,\"626\":6496.8862304688,\"627\":6496.8862304688,\"628\":6496.8862304688,\"629\":6496.8862304688,\"630\":6496.8862304688,\"631\":6496.8862304688,\"632\":6496.8862304688,\"633\":6496.8862304688,\"634\":6496.8862304688,\"635\":6496.8862304688,\"636\":6496.8862304688,\"637\":6496.8862304688,\"638\":6496.8862304688,\"639\":6496.8862304688,\"640\":6496.8862304688,\"641\":6496.8862304688,\"642\":6496.8862304688,\"643\":6496.8862304688,\"644\":6496.8862304688,\"645\":6496.8862304688,\"646\":6496.8862304688,\"647\":6496.8862304688,\"648\":6496.8862304688,\"649\":6496.8862304688,\"650\":6496.8862304688,\"651\":6496.8862304688,\"652\":6496.8862304688,\"653\":6496.8862304688,\"654\":6496.8862304688,\"655\":6496.8862304688,\"656\":6496.8862304688,\"657\":6496.8862304688,\"658\":6496.8862304688,\"659\":6496.8862304688,\"660\":6496.8862304688,\"661\":6496.8862304688,\"662\":6496.8862304688,\"663\":6496.8862304688,\"664\":6496.8862304688,\"665\":6496.8862304688,\"666\":6496.8862304688,\"667\":6496.8862304688,\"668\":6496.8862304688,\"669\":6496.8862304688,\"670\":6496.8862304688,\"671\":6496.8862304688,\"672\":6496.8862304688,\"673\":6496.8862304688,\"674\":6496.8862304688,\"675\":6496.8862304688,\"676\":6496.8862304688,\"677\":6496.8862304688,\"678\":6496.8862304688,\"679\":6496.8862304688,\"680\":6496.8862304688,\"681\":6496.8862304688,\"682\":6496.8862304688,\"683\":6496.8862304688,\"684\":6496.8862304688,\"685\":6496.8862304688,\"686\":6496.8862304688,\"687\":6496.8862304688,\"688\":6496.8862304688,\"689\":6496.8862304688,\"690\":6496.8862304688,\"691\":6496.8862304688,\"692\":6496.8862304688,\"693\":6496.8862304688,\"694\":6496.8862304688,\"695\":6496.8862304688,\"696\":6496.8862304688,\"697\":6496.8862304688,\"698\":6496.8862304688,\"699\":6496.8862304688,\"700\":6496.8862304688,\"701\":6496.8862304688,\"702\":6496.8862304688,\"703\":6496.8862304688,\"704\":6496.8862304688,\"705\":6496.8862304688,\"706\":6496.8862304688,\"707\":6496.8862304688,\"708\":6496.8862304688,\"709\":6496.8862304688,\"710\":6496.8862304688,\"711\":6496.8862304688,\"712\":6496.8862304688,\"713\":6496.8862304688,\"714\":6496.8862304688,\"715\":6496.8862304688,\"716\":6496.8862304688,\"717\":6496.8862304688,\"718\":6496.8862304688,\"719\":6496.8862304688,\"720\":6496.8862304688,\"721\":6496.8862304688,\"722\":6496.8862304688,\"723\":6496.8862304688,\"724\":6496.8862304688,\"725\":6496.8862304688,\"726\":6496.8862304688,\"727\":6496.8862304688,\"728\":6496.8862304688,\"729\":6496.8862304688,\"730\":6496.8862304688,\"731\":6496.8862304688,\"732\":6496.8862304688,\"733\":6496.8862304688,\"734\":6496.8862304688,\"735\":6496.8862304688,\"736\":6496.8862304688,\"737\":6496.8862304688,\"738\":6496.8862304688,\"739\":6496.8862304688,\"740\":6496.8862304688,\"741\":6496.8862304688,\"742\":6496.8862304688,\"743\":6496.8862304688,\"744\":6496.8862304688,\"745\":6496.8862304688,\"746\":6496.8862304688,\"747\":6496.8862304688,\"748\":6496.8862304688,\"749\":6496.8862304688,\"750\":6496.8862304688,\"751\":6496.8862304688,\"752\":6496.8862304688,\"753\":6496.8862304688,\"754\":6496.8862304688,\"755\":6496.8862304688,\"756\":6496.8862304688,\"757\":6496.8862304688,\"758\":6496.8862304688,\"759\":6496.8862304688,\"760\":6496.8862304688,\"761\":6496.8862304688,\"762\":6496.8862304688,\"763\":6496.8862304688,\"764\":6496.8862304688,\"765\":6496.8862304688,\"766\":6496.8862304688,\"767\":6496.8862304688,\"768\":6496.8862304688,\"769\":6496.8862304688,\"770\":6496.8862304688,\"771\":6496.8862304688,\"772\":6496.8862304688,\"773\":6496.8862304688,\"774\":6496.8862304688,\"775\":6496.8862304688,\"776\":6496.8862304688,\"777\":6496.8862304688,\"778\":6496.8862304688,\"779\":6496.8862304688,\"780\":6496.8862304688,\"781\":6496.8862304688,\"782\":6496.8862304688,\"783\":6496.8862304688,\"784\":6496.8862304688,\"785\":6496.8862304688,\"786\":6496.8862304688,\"787\":6496.8862304688,\"788\":6496.8862304688,\"789\":6496.8862304688,\"790\":6496.8862304688,\"791\":6496.8862304688,\"792\":6496.8862304688,\"793\":6496.8862304688,\"794\":6496.8862304688,\"795\":6496.8862304688,\"796\":6496.8862304688,\"797\":6496.8862304688,\"798\":6496.8862304688,\"799\":6496.8862304688,\"800\":6496.8862304688,\"801\":6496.8862304688,\"802\":6496.8862304688,\"803\":6496.8862304688,\"804\":6496.8862304688,\"805\":6496.8862304688,\"806\":6496.8862304688,\"807\":6496.8862304688,\"808\":6496.8862304688,\"809\":6496.8862304688,\"810\":6496.8862304688,\"811\":6496.8862304688,\"812\":6496.8862304688,\"813\":6496.8862304688,\"814\":6496.8862304688,\"815\":6496.8862304688,\"816\":6496.8862304688,\"817\":6496.8862304688,\"818\":6496.8862304688,\"819\":6496.8862304688,\"820\":6496.8862304688,\"821\":6496.8862304688,\"822\":6496.8862304688,\"823\":6496.8862304688,\"824\":6496.8862304688,\"825\":6496.8862304688,\"826\":6496.8862304688,\"827\":6496.8862304688,\"828\":6496.8862304688,\"829\":6496.8862304688,\"830\":6496.8862304688,\"831\":6496.8862304688,\"832\":6496.8862304688,\"833\":6496.8862304688,\"834\":6496.8862304688,\"835\":6496.8862304688,\"836\":6496.8862304688,\"837\":6496.8862304688,\"838\":6496.8862304688,\"839\":6496.8862304688,\"840\":6496.8862304688,\"841\":6496.8862304688,\"842\":6496.8862304688,\"843\":6496.8862304688,\"844\":6496.8862304688,\"845\":6496.8862304688,\"846\":6496.8862304688,\"847\":6496.8862304688,\"848\":6496.8862304688,\"849\":6496.8862304688,\"850\":6496.8862304688,\"851\":6496.8862304688,\"852\":6496.8862304688,\"853\":6496.8862304688,\"854\":6496.8862304688,\"855\":6496.8862304688,\"856\":6496.8862304688,\"857\":6496.8862304688,\"858\":6496.8862304688,\"859\":6496.8862304688,\"860\":6496.8862304688,\"861\":6496.8862304688,\"862\":6496.8862304688,\"863\":6496.8862304688,\"864\":6496.8862304688,\"865\":6496.8862304688,\"866\":6496.8862304688,\"867\":6496.8862304688,\"868\":6496.8862304688,\"869\":6496.8862304688,\"870\":6496.8862304688,\"871\":6496.8862304688,\"872\":6496.8862304688,\"873\":6496.8862304688,\"874\":6496.8862304688,\"875\":6496.8862304688,\"876\":6496.8862304688,\"877\":6496.8862304688,\"878\":6496.8862304688,\"879\":6496.8862304688,\"880\":6496.8862304688,\"881\":6496.8862304688,\"882\":6496.8862304688,\"883\":6496.8862304688,\"884\":6496.8862304688,\"885\":6496.8862304688,\"886\":6496.8862304688,\"887\":6496.8862304688,\"888\":6496.8862304688,\"889\":6496.8862304688,\"890\":6496.8862304688,\"891\":6496.8862304688,\"892\":6496.8862304688,\"893\":6496.8862304688,\"894\":6496.8862304688,\"895\":6496.8862304688,\"896\":6496.8862304688,\"897\":6496.8862304688,\"898\":6496.8862304688,\"899\":6496.8862304688,\"900\":6496.8862304688,\"901\":6496.8862304688,\"902\":6496.8862304688,\"903\":6496.8862304688,\"904\":6496.8862304688,\"905\":6496.8862304688,\"906\":6496.8862304688,\"907\":6496.8862304688,\"908\":6496.8862304688,\"909\":6496.8862304688,\"910\":6496.8862304688,\"911\":6496.8862304688,\"912\":6496.8862304688,\"913\":6496.8862304688,\"914\":6496.8862304688,\"915\":6496.8862304688,\"916\":6496.8862304688,\"917\":6496.8862304688,\"918\":6496.8862304688,\"919\":6496.8862304688,\"920\":6496.8862304688,\"921\":6496.8862304688,\"922\":6496.8862304688,\"923\":6496.8862304688,\"924\":6496.8862304688,\"925\":6496.8862304688,\"926\":6496.8862304688,\"927\":6496.8862304688,\"928\":6496.8862304688,\"929\":6496.8862304688,\"930\":6496.8862304688,\"931\":6496.8862304688,\"932\":6496.8862304688,\"933\":6496.8862304688,\"934\":6496.8862304688,\"935\":6496.8862304688,\"936\":6496.8862304688,\"937\":6496.8862304688,\"938\":6496.8862304688,\"939\":6496.8862304688,\"940\":6496.8862304688,\"941\":6496.8862304688,\"942\":6496.8862304688,\"943\":6496.8862304688,\"944\":6496.8862304688,\"945\":6496.8862304688,\"946\":6496.8862304688,\"947\":6496.8862304688,\"948\":6496.8862304688,\"949\":6496.8862304688,\"950\":6496.8862304688,\"951\":6496.8862304688,\"952\":6496.8862304688,\"953\":6496.8862304688,\"954\":6496.8862304688,\"955\":6496.8862304688,\"956\":6496.8862304688,\"957\":6496.8862304688,\"958\":6496.8862304688,\"959\":6496.8862304688,\"960\":6496.8862304688,\"961\":6496.8862304688,\"962\":6496.8862304688,\"963\":6496.8862304688,\"964\":6496.8862304688,\"965\":6496.8862304688,\"966\":6496.8862304688,\"967\":6496.8862304688,\"968\":6496.8862304688,\"969\":6496.8862304688,\"970\":6496.8862304688,\"971\":6496.8862304688,\"972\":6496.8862304688,\"973\":6496.8862304688,\"974\":6496.8862304688,\"975\":6496.8862304688,\"976\":6496.8862304688,\"977\":6496.8862304688,\"978\":6496.8862304688,\"979\":6496.8862304688,\"980\":6496.8862304688,\"981\":6496.8862304688,\"982\":6496.8862304688,\"983\":6496.8862304688,\"984\":6496.8862304688,\"985\":6496.8862304688,\"986\":6496.8862304688,\"987\":6496.8862304688,\"988\":6496.8862304688,\"989\":6496.8862304688,\"990\":6496.8862304688,\"991\":6496.8862304688,\"992\":6496.8862304688,\"993\":6496.8862304688,\"994\":6496.8862304688,\"995\":6496.8862304688,\"996\":6496.8862304688,\"997\":6496.8862304688,\"998\":6496.8862304688,\"999\":6496.8862304688,\"1000\":6496.8862304688,\"1001\":6496.8862304688,\"1002\":6496.8862304688,\"1003\":6496.8862304688,\"1004\":6496.8862304688,\"1005\":6496.8862304688,\"1006\":6496.8862304688,\"1007\":6496.8862304688,\"1008\":6496.8862304688,\"1009\":6496.8862304688,\"1010\":6496.8862304688,\"1011\":6496.8862304688,\"1012\":6496.8862304688,\"1013\":6496.8862304688,\"1014\":6496.8862304688,\"1015\":6496.8862304688,\"1016\":6496.8862304688,\"1017\":6496.8862304688,\"1018\":6496.8862304688,\"1019\":6496.8862304688,\"1020\":6496.8862304688,\"1021\":6496.8862304688,\"1022\":6496.8862304688,\"1023\":6496.8862304688,\"1024\":6496.8862304688,\"1025\":6496.8862304688,\"1026\":6496.8862304688,\"1027\":6496.8862304688,\"1028\":6496.8862304688,\"1029\":6496.8862304688,\"1030\":6496.8862304688,\"1031\":6496.8862304688,\"1032\":6496.8862304688,\"1033\":6496.8862304688,\"1034\":6496.8862304688,\"1035\":6496.8862304688,\"1036\":6496.8862304688,\"1037\":6496.8862304688,\"1038\":6496.8862304688,\"1039\":6496.8862304688,\"1040\":6496.8862304688,\"1041\":6496.8862304688,\"1042\":6496.8862304688,\"1043\":6496.8862304688,\"1044\":6496.8862304688,\"1045\":6496.8862304688,\"1046\":6496.8862304688,\"1047\":6496.8862304688,\"1048\":6496.8862304688,\"1049\":6496.8862304688,\"1050\":6496.8862304688,\"1051\":6496.8862304688,\"1052\":6496.8862304688,\"1053\":6496.8862304688,\"1054\":6496.8862304688,\"1055\":6496.8862304688,\"1056\":6496.8862304688,\"1057\":6496.8862304688,\"1058\":6496.8862304688,\"1059\":6496.8862304688,\"1060\":6496.8862304688,\"1061\":6496.8862304688,\"1062\":6496.8862304688,\"1063\":6496.8862304688,\"1064\":6496.8862304688,\"1065\":6496.8862304688,\"1066\":6496.8862304688,\"1067\":6496.8862304688,\"1068\":6496.8862304688,\"1069\":6496.8862304688,\"1070\":6496.8862304688,\"1071\":6496.8862304688,\"1072\":6496.8862304688,\"1073\":6496.8862304688,\"1074\":6496.8862304688,\"1075\":6496.8862304688,\"1076\":6496.8862304688,\"1077\":6496.8862304688,\"1078\":6496.8862304688,\"1079\":6496.8862304688,\"1080\":6496.8862304688,\"1081\":6496.8862304688,\"1082\":6496.8862304688,\"1083\":6496.8862304688,\"1084\":6496.8862304688,\"1085\":6496.8862304688,\"1086\":6496.8862304688,\"1087\":6496.8862304688,\"1088\":6496.8862304688,\"1089\":6496.8862304688,\"1090\":6496.8862304688,\"1091\":6496.8862304688,\"1092\":6496.8862304688,\"1093\":6496.8862304688,\"1094\":6496.8862304688,\"1095\":6496.8862304688,\"1096\":6496.8862304688,\"1097\":6496.8862304688,\"1098\":6496.8862304688,\"1099\":6496.8862304688,\"1100\":6496.8862304688,\"1101\":6496.8862304688,\"1102\":6496.8862304688,\"1103\":6496.8862304688,\"1104\":6496.8862304688,\"1105\":6496.8862304688,\"1106\":6496.8862304688,\"1107\":6496.8862304688,\"1108\":6496.8862304688,\"1109\":6496.8862304688,\"1110\":6496.8862304688,\"1111\":6496.8862304688,\"1112\":6496.8862304688,\"1113\":6496.8862304688,\"1114\":6496.8862304688,\"1115\":6496.8862304688,\"1116\":6496.8862304688,\"1117\":6496.8862304688,\"1118\":6496.8862304688,\"1119\":6496.8862304688,\"1120\":6496.8862304688,\"1121\":6496.8862304688,\"1122\":6496.8862304688,\"1123\":6496.8862304688,\"1124\":6496.8862304688,\"1125\":6496.8862304688,\"1126\":6496.8862304688,\"1127\":6496.8862304688,\"1128\":6496.8862304688,\"1129\":6496.8862304688,\"1130\":6496.8862304688,\"1131\":6496.8862304688,\"1132\":6496.8862304688,\"1133\":6496.8862304688,\"1134\":6496.8862304688,\"1135\":6496.8862304688,\"1136\":6496.8862304688,\"1137\":6496.8862304688,\"1138\":6496.8862304688,\"1139\":6496.8862304688,\"1140\":6496.8862304688,\"1141\":6496.8862304688,\"1142\":6496.8862304688,\"1143\":6496.8862304688,\"1144\":6496.8862304688,\"1145\":6496.8862304688,\"1146\":6496.8862304688,\"1147\":6496.8862304688,\"1148\":6496.8862304688,\"1149\":6496.8862304688,\"1150\":6496.8862304688,\"1151\":6496.8862304688,\"1152\":6496.8862304688,\"1153\":6496.8862304688,\"1154\":6496.8862304688,\"1155\":6496.8862304688,\"1156\":6496.8862304688,\"1157\":6496.8862304688,\"1158\":6496.8862304688,\"1159\":6496.8862304688,\"1160\":6496.8862304688,\"1161\":6496.8862304688,\"1162\":6496.8862304688,\"1163\":6496.8862304688,\"1164\":6496.8862304688,\"1165\":6496.8862304688,\"1166\":6496.8862304688,\"1167\":6496.8862304688,\"1168\":6496.8862304688,\"1169\":6496.8862304688,\"1170\":6496.8862304688,\"1171\":6496.8862304688,\"1172\":6496.8862304688,\"1173\":6496.8862304688,\"1174\":6496.8862304688,\"1175\":6496.8862304688,\"1176\":6496.8862304688,\"1177\":6496.8862304688,\"1178\":6496.8862304688,\"1179\":6496.8862304688,\"1180\":6496.8862304688,\"1181\":6496.8862304688,\"1182\":6496.8862304688,\"1183\":6496.8862304688,\"1184\":6496.8862304688,\"1185\":6496.8862304688,\"1186\":6496.8862304688,\"1187\":6496.8862304688,\"1188\":6496.8862304688,\"1189\":6496.8862304688,\"1190\":6496.8862304688,\"1191\":6496.8862304688,\"1192\":6496.8862304688,\"1193\":6496.8862304688,\"1194\":6496.8862304688,\"1195\":6496.8862304688,\"1196\":6496.8862304688,\"1197\":6496.8862304688,\"1198\":6496.8862304688,\"1199\":6496.8862304688,\"1200\":6496.8862304688,\"1201\":6496.8862304688,\"1202\":6496.8862304688,\"1203\":6496.8862304688,\"1204\":6496.8862304688,\"1205\":6496.8862304688,\"1206\":6496.8862304688,\"1207\":6496.8862304688,\"1208\":6496.8862304688,\"1209\":6496.8862304688,\"1210\":6496.8862304688,\"1211\":6496.8862304688,\"1212\":6496.8862304688,\"1213\":6496.8862304688,\"1214\":6496.8862304688,\"1215\":6496.8862304688,\"1216\":6496.8862304688,\"1217\":6496.8862304688,\"1218\":6496.8862304688,\"1219\":6496.8862304688,\"1220\":6496.8862304688,\"1221\":6496.8862304688,\"1222\":6496.8862304688,\"1223\":6496.8862304688,\"1224\":6496.8862304688,\"1225\":6496.8862304688,\"1226\":6496.8862304688,\"1227\":6496.8862304688,\"1228\":6496.8862304688,\"1229\":6496.8862304688,\"1230\":6496.8862304688,\"1231\":6496.8862304688,\"1232\":6496.8862304688,\"1233\":6496.8862304688,\"1234\":6496.8862304688,\"1235\":6496.8862304688,\"1236\":6496.8862304688,\"1237\":6496.8862304688,\"1238\":6496.8862304688,\"1239\":6496.8862304688,\"1240\":6496.8862304688,\"1241\":6496.8862304688,\"1242\":6496.8862304688,\"1243\":6496.8862304688,\"1244\":6496.8862304688,\"1245\":6496.8862304688,\"1246\":6496.8862304688,\"1247\":6496.8862304688,\"1248\":6496.8862304688,\"1249\":6496.8862304688,\"1250\":6496.8862304688,\"1251\":6496.8862304688,\"1252\":6496.8862304688,\"1253\":6496.8862304688,\"1254\":6496.8862304688,\"1255\":6496.8862304688,\"1256\":6496.8862304688,\"1257\":6496.8862304688,\"1258\":6496.8862304688,\"1259\":6496.8862304688,\"1260\":6496.8862304688,\"1261\":6496.8862304688,\"1262\":6496.8862304688,\"1263\":6496.8862304688,\"1264\":6496.8862304688,\"1265\":6496.8862304688,\"1266\":6496.8862304688,\"1267\":6496.8862304688,\"1268\":6496.8862304688,\"1269\":6496.8862304688,\"1270\":6496.8862304688,\"1271\":6496.8862304688,\"1272\":6496.8862304688,\"1273\":6496.8862304688,\"1274\":6496.8862304688,\"1275\":6496.8862304688,\"1276\":6496.8862304688,\"1277\":6496.8862304688,\"1278\":6496.8862304688,\"1279\":6496.8862304688,\"1280\":6496.8862304688,\"1281\":6496.8862304688,\"1282\":6496.8862304688,\"1283\":6496.8862304688,\"1284\":6496.8862304688,\"1285\":6496.8862304688,\"1286\":6496.8862304688,\"1287\":6496.8862304688,\"1288\":6496.8862304688,\"1289\":6496.8862304688,\"1290\":6496.8862304688,\"1291\":6496.8862304688,\"1292\":6496.8862304688,\"1293\":6496.8862304688,\"1294\":6496.8862304688,\"1295\":6496.8862304688,\"1296\":6496.8862304688,\"1297\":6496.8862304688,\"1298\":6496.8862304688,\"1299\":6496.8862304688,\"1300\":6496.8862304688,\"1301\":6496.8862304688,\"1302\":6496.8862304688,\"1303\":6496.8862304688,\"1304\":6496.8862304688,\"1305\":6496.8862304688,\"1306\":6496.8862304688,\"1307\":6496.8862304688,\"1308\":6496.8862304688,\"1309\":6496.8862304688,\"1310\":6496.8862304688,\"1311\":6496.8862304688,\"1312\":6496.8862304688,\"1313\":6496.8862304688,\"1314\":6496.8862304688,\"1315\":6496.8862304688,\"1316\":6496.8862304688,\"1317\":6496.8862304688,\"1318\":6496.8862304688,\"1319\":6496.8862304688,\"1320\":6496.8862304688,\"1321\":6496.8862304688,\"1322\":6496.8862304688,\"1323\":6496.8862304688,\"1324\":6496.8862304688,\"1325\":6496.8862304688,\"1326\":6496.8862304688,\"1327\":6496.8862304688,\"1328\":6496.8862304688,\"1329\":6496.8862304688,\"1330\":6496.8862304688,\"1331\":6496.8862304688,\"1332\":6496.8862304688,\"1333\":6496.8862304688,\"1334\":6496.8862304688,\"1335\":6496.8862304688,\"1336\":6496.8862304688,\"1337\":6496.8862304688,\"1338\":6496.8862304688,\"1339\":6496.8862304688,\"1340\":6496.8862304688,\"1341\":6496.8862304688,\"1342\":6496.8862304688,\"1343\":6496.8862304688,\"1344\":6496.8862304688,\"1345\":6496.8862304688,\"1346\":6496.8862304688,\"1347\":6496.8862304688,\"1348\":6496.8862304688,\"1349\":6496.8862304688,\"1350\":6496.8862304688,\"1351\":6496.8862304688,\"1352\":6496.8862304688,\"1353\":6496.8862304688,\"1354\":6496.8862304688,\"1355\":6496.8862304688,\"1356\":6496.8862304688,\"1357\":6496.8862304688,\"1358\":6496.8862304688,\"1359\":6496.8862304688,\"1360\":6496.8862304688,\"1361\":6496.8862304688,\"1362\":6496.8862304688,\"1363\":6496.8862304688,\"1364\":6496.8862304688,\"1365\":6496.8862304688,\"1366\":6496.8862304688,\"1367\":6496.8862304688,\"1368\":6496.8862304688,\"1369\":6496.8862304688,\"1370\":6496.8862304688,\"1371\":6496.8862304688,\"1372\":6496.8862304688,\"1373\":6496.8862304688,\"1374\":6496.8862304688,\"1375\":6496.8862304688,\"1376\":6496.8862304688,\"1377\":6496.8862304688,\"1378\":6496.8862304688,\"1379\":6496.8862304688,\"1380\":6496.8862304688,\"1381\":6496.8862304688,\"1382\":6496.8862304688,\"1383\":6496.8862304688,\"1384\":6496.8862304688,\"1385\":6496.8862304688,\"1386\":6496.8862304688,\"1387\":6496.8862304688,\"1388\":6496.8862304688,\"1389\":6496.8862304688,\"1390\":6496.8862304688,\"1391\":6496.8862304688,\"1392\":6496.8862304688,\"1393\":6496.8862304688,\"1394\":6496.8862304688,\"1395\":6496.8862304688,\"1396\":6496.8862304688,\"1397\":6496.8862304688,\"1398\":6496.8862304688,\"1399\":6496.8862304688,\"1400\":6496.8862304688,\"1401\":6496.8862304688,\"1402\":6496.8862304688,\"1403\":6496.8862304688,\"1404\":6496.8862304688,\"1405\":6496.8862304688,\"1406\":6496.8862304688,\"1407\":6496.8862304688,\"1408\":6496.8862304688,\"1409\":6496.8862304688,\"1410\":6496.8862304688,\"1411\":6496.8862304688,\"1412\":6496.8862304688,\"1413\":6496.8862304688,\"1414\":6496.8862304688,\"1415\":6496.8862304688,\"1416\":6496.8862304688,\"1417\":6496.8862304688,\"1418\":6496.8862304688,\"1419\":6496.8862304688,\"1420\":6496.8862304688,\"1421\":6496.8862304688,\"1422\":6496.8862304688,\"1423\":6496.8862304688,\"1424\":6496.8862304688,\"1425\":6496.8862304688,\"1426\":6496.8862304688,\"1427\":6496.8862304688,\"1428\":6496.8862304688,\"1429\":6496.8862304688,\"1430\":6496.8862304688,\"1431\":6496.8862304688,\"1432\":6496.8862304688,\"1433\":6496.8862304688,\"1434\":6496.8862304688,\"1435\":6496.8862304688,\"1436\":6496.8862304688,\"1437\":6496.8862304688,\"1438\":6496.8862304688,\"1439\":6496.8862304688,\"1440\":6496.8862304688,\"1441\":6496.8862304688,\"1442\":6496.8862304688,\"1443\":6496.8862304688,\"1444\":6496.8862304688,\"1445\":6496.8862304688,\"1446\":6496.8862304688,\"1447\":6496.8862304688,\"1448\":6496.8862304688,\"1449\":6496.8862304688,\"1450\":6496.8862304688,\"1451\":6496.8862304688,\"1452\":6496.8862304688,\"1453\":6496.8862304688,\"1454\":6496.8862304688,\"1455\":6496.8862304688,\"1456\":6496.8862304688,\"1457\":6496.8862304688,\"1458\":6496.8862304688,\"1459\":6496.8862304688,\"1460\":6496.8862304688,\"1461\":6496.8862304688,\"1462\":6496.8862304688,\"1463\":6496.8862304688,\"1464\":6496.8862304688,\"1465\":6496.8862304688,\"1466\":6496.8862304688,\"1467\":6496.8862304688,\"1468\":6496.8862304688,\"1469\":6496.8862304688,\"1470\":6496.8862304688,\"1471\":6496.8862304688,\"1472\":6496.8862304688,\"1473\":6496.8862304688,\"1474\":6496.8862304688,\"1475\":6496.8862304688,\"1476\":6496.8862304688,\"1477\":6496.8862304688,\"1478\":6496.8862304688,\"1479\":6496.8862304688,\"1480\":6496.8862304688,\"1481\":6496.8862304688,\"1482\":6496.8862304688,\"1483\":6496.8862304688,\"1484\":6496.8862304688,\"1485\":6496.8862304688,\"1486\":6496.8862304688,\"1487\":6496.8862304688,\"1488\":6496.8862304688,\"1489\":6496.8862304688,\"1490\":6496.8862304688,\"1491\":6496.8862304688,\"1492\":6496.8862304688,\"1493\":6496.8862304688,\"1494\":6496.8862304688,\"1495\":6496.8862304688,\"1496\":6496.8862304688,\"1497\":6496.8862304688,\"1498\":6496.8862304688,\"1499\":6496.8862304688,\"1500\":6496.8862304688,\"1501\":6496.8862304688,\"1502\":6496.8862304688,\"1503\":6496.8862304688,\"1504\":6496.8862304688,\"1505\":6496.8862304688,\"1506\":6496.8862304688,\"1507\":6496.8862304688,\"1508\":6496.8862304688,\"1509\":6496.8862304688,\"1510\":6496.8862304688,\"1511\":6496.8862304688,\"1512\":6496.8862304688,\"1513\":6496.8862304688,\"1514\":6496.8862304688,\"1515\":6496.8862304688,\"1516\":6496.8862304688,\"1517\":6496.8862304688,\"1518\":6496.8862304688,\"1519\":6496.8862304688,\"1520\":6496.8862304688,\"1521\":6496.8862304688,\"1522\":6496.8862304688,\"1523\":6496.8862304688,\"1524\":6496.8862304688,\"1525\":6496.8862304688,\"1526\":6496.8862304688,\"1527\":6496.8862304688,\"1528\":6496.8862304688,\"1529\":6496.8862304688,\"1530\":6496.8862304688,\"1531\":6496.8862304688,\"1532\":6496.8862304688,\"1533\":6496.8862304688,\"1534\":6496.8862304688,\"1535\":6496.8862304688,\"1536\":6496.8862304688,\"1537\":6496.8862304688,\"1538\":6496.8862304688,\"1539\":6496.8862304688,\"1540\":6496.8862304688,\"1541\":6496.8862304688,\"1542\":6496.8862304688,\"1543\":6496.8862304688,\"1544\":6496.8862304688,\"1545\":6496.8862304688,\"1546\":6496.8862304688,\"1547\":6496.8862304688,\"1548\":6496.8862304688,\"1549\":6496.8862304688,\"1550\":6496.8862304688,\"1551\":6496.8862304688,\"1552\":6496.8862304688,\"1553\":6496.8862304688,\"1554\":6496.8862304688,\"1555\":6496.8862304688,\"1556\":6496.8862304688,\"1557\":6496.8862304688,\"1558\":6496.8862304688,\"1559\":6496.8862304688,\"1560\":6496.8862304688,\"1561\":6496.8862304688,\"1562\":6496.8862304688,\"1563\":6496.8862304688,\"1564\":6496.8862304688,\"1565\":6496.8862304688,\"1566\":6496.8862304688,\"1567\":6496.8862304688,\"1568\":6496.8862304688,\"1569\":6496.8862304688,\"1570\":6496.8862304688,\"1571\":6496.8862304688,\"1572\":6496.8862304688,\"1573\":6496.8862304688,\"1574\":6496.8862304688,\"1575\":6496.8862304688,\"1576\":6496.8862304688,\"1577\":6496.8862304688,\"1578\":6496.8862304688,\"1579\":6496.8862304688,\"1580\":6496.8862304688,\"1581\":6496.8862304688,\"1582\":6496.8862304688,\"1583\":6496.8862304688,\"1584\":6496.8862304688,\"1585\":6496.8862304688,\"1586\":6496.8862304688,\"1587\":6496.8862304688,\"1588\":6496.8862304688,\"1589\":6496.8862304688,\"1590\":6496.8862304688,\"1591\":6496.8862304688,\"1592\":6496.8862304688,\"1593\":6496.8862304688,\"1594\":6496.8862304688,\"1595\":6496.8862304688,\"1596\":6496.8862304688,\"1597\":6496.8862304688,\"1598\":6496.8862304688,\"1599\":6496.8862304688,\"1600\":6496.8862304688,\"1601\":6496.8862304688,\"1602\":6496.8862304688,\"1603\":6496.8862304688,\"1604\":6496.8862304688,\"1605\":6496.8862304688,\"1606\":6496.8862304688,\"1607\":6496.8862304688,\"1608\":6496.8862304688,\"1609\":6496.8862304688,\"1610\":6496.8862304688,\"1611\":6496.8862304688,\"1612\":6496.8862304688,\"1613\":6496.8862304688,\"1614\":6496.8862304688,\"1615\":6496.8862304688,\"1616\":6496.8862304688,\"1617\":6496.8862304688,\"1618\":6496.8862304688,\"1619\":6496.8862304688,\"1620\":6496.8862304688,\"1621\":6496.8862304688,\"1622\":6496.8862304688,\"1623\":6496.8862304688,\"1624\":6496.8862304688,\"1625\":6496.8862304688,\"1626\":6496.8862304688,\"1627\":6496.8862304688,\"1628\":6496.8862304688,\"1629\":6496.8862304688,\"1630\":6496.8862304688,\"1631\":6496.8862304688,\"1632\":6496.8862304688,\"1633\":6496.8862304688,\"1634\":6496.8862304688,\"1635\":6496.8862304688,\"1636\":6496.8862304688,\"1637\":6496.8862304688,\"1638\":6496.8862304688,\"1639\":6496.8862304688,\"1640\":6496.8862304688,\"1641\":6496.8862304688,\"1642\":6496.8862304688,\"1643\":6496.8862304688,\"1644\":6496.8862304688,\"1645\":6496.8862304688,\"1646\":6496.8862304688,\"1647\":6496.8862304688,\"1648\":6496.8862304688,\"1649\":6496.8862304688,\"1650\":6496.8862304688,\"1651\":6496.8862304688,\"1652\":6496.8862304688,\"1653\":6496.8862304688,\"1654\":6496.8862304688,\"1655\":6496.8862304688,\"1656\":6496.8862304688,\"1657\":6496.8862304688,\"1658\":6496.8862304688,\"1659\":6496.8862304688,\"1660\":6496.8862304688,\"1661\":6496.8862304688,\"1662\":6496.8862304688,\"1663\":6496.8862304688,\"1664\":6496.8862304688,\"1665\":6496.8862304688,\"1666\":6496.8862304688,\"1667\":6496.8862304688,\"1668\":6496.8862304688,\"1669\":6496.8862304688,\"1670\":6496.8862304688,\"1671\":6496.8862304688,\"1672\":6496.8862304688,\"1673\":6496.8862304688,\"1674\":6496.8862304688,\"1675\":6496.8862304688,\"1676\":6496.8862304688,\"1677\":6496.8862304688,\"1678\":6496.8862304688,\"1679\":6496.8862304688,\"1680\":6496.8862304688,\"1681\":6496.8862304688,\"1682\":6496.8862304688,\"1683\":6496.8862304688,\"1684\":6496.8862304688,\"1685\":6496.8862304688,\"1686\":6496.8862304688,\"1687\":6496.8862304688,\"1688\":6496.8862304688,\"1689\":6496.8862304688,\"1690\":6496.8862304688,\"1691\":6496.8862304688,\"1692\":6496.8862304688,\"1693\":6496.8862304688,\"1694\":6496.8862304688,\"1695\":6496.8862304688,\"1696\":6496.8862304688,\"1697\":6496.8862304688,\"1698\":6496.8862304688,\"1699\":6496.8862304688,\"1700\":6496.8862304688,\"1701\":6496.8862304688,\"1702\":6496.8862304688,\"1703\":6496.8862304688,\"1704\":6496.8862304688,\"1705\":6496.8862304688,\"1706\":6496.8862304688,\"1707\":6496.8862304688,\"1708\":6496.8862304688,\"1709\":6496.8862304688,\"1710\":6496.8862304688,\"1711\":6496.8862304688,\"1712\":6496.8862304688,\"1713\":6496.8862304688,\"1714\":6496.8862304688,\"1715\":6496.8862304688,\"1716\":6496.8862304688,\"1717\":6496.8862304688,\"1718\":6496.8862304688,\"1719\":6496.8862304688,\"1720\":6496.8862304688,\"1721\":6496.8862304688,\"1722\":6496.8862304688,\"1723\":6496.8862304688,\"1724\":6496.8862304688,\"1725\":6496.8862304688,\"1726\":6496.8862304688,\"1727\":6496.8862304688,\"1728\":6496.8862304688,\"1729\":6496.8862304688,\"1730\":6496.8862304688,\"1731\":6496.8862304688,\"1732\":6496.8862304688,\"1733\":6496.8862304688,\"1734\":6496.8862304688,\"1735\":6496.8862304688,\"1736\":6496.8862304688,\"1737\":6496.8862304688,\"1738\":6496.8862304688,\"1739\":6496.8862304688,\"1740\":6496.8862304688,\"1741\":6496.8862304688,\"1742\":6496.8862304688,\"1743\":6496.8862304688,\"1744\":6496.8862304688,\"1745\":6496.8862304688,\"1746\":6496.8862304688,\"1747\":6496.8862304688,\"1748\":6496.8862304688,\"1749\":6496.8862304688,\"1750\":6496.8862304688,\"1751\":6496.8862304688,\"1752\":6496.8862304688,\"1753\":6496.8862304688,\"1754\":6496.8862304688,\"1755\":6496.8862304688,\"1756\":6496.8862304688,\"1757\":6496.8862304688,\"1758\":6496.8862304688,\"1759\":6496.8862304688,\"1760\":6496.8862304688,\"1761\":6496.8862304688,\"1762\":6496.8862304688,\"1763\":6496.8862304688,\"1764\":6496.8862304688,\"1765\":6496.8862304688,\"1766\":6496.8862304688,\"1767\":6496.8862304688,\"1768\":6496.8862304688,\"1769\":6496.8862304688,\"1770\":6496.8862304688,\"1771\":6496.8862304688,\"1772\":6496.8862304688,\"1773\":6496.8862304688,\"1774\":6496.8862304688,\"1775\":6496.8862304688,\"1776\":6496.8862304688,\"1777\":6496.8862304688,\"1778\":6496.8862304688,\"1779\":6496.8862304688,\"1780\":6496.8862304688,\"1781\":6496.8862304688,\"1782\":6496.8862304688,\"1783\":6496.8862304688,\"1784\":6496.8862304688,\"1785\":6496.8862304688,\"1786\":6496.8862304688,\"1787\":6496.8862304688,\"1788\":6496.8862304688,\"1789\":6496.8862304688,\"1790\":6496.8862304688,\"1791\":6496.8862304688,\"1792\":6496.8862304688,\"1793\":6496.8862304688,\"1794\":6496.8862304688,\"1795\":6496.8862304688,\"1796\":6496.8862304688,\"1797\":6496.8862304688,\"1798\":6496.8862304688,\"1799\":6496.8862304688,\"1800\":6496.8862304688,\"1801\":6496.8862304688,\"1802\":6496.8862304688,\"1803\":6496.8862304688,\"1804\":6496.8862304688,\"1805\":6496.8862304688,\"1806\":6496.8862304688,\"1807\":6496.8862304688,\"1808\":6496.8862304688,\"1809\":6496.8862304688,\"1810\":6496.8862304688,\"1811\":6496.8862304688,\"1812\":6496.8862304688,\"1813\":6496.8862304688,\"1814\":6496.8862304688,\"1815\":6496.8862304688,\"1816\":6496.8862304688,\"1817\":6496.8862304688,\"1818\":6496.8862304688,\"1819\":6496.8862304688,\"1820\":6496.8862304688,\"1821\":6496.8862304688,\"1822\":6496.8862304688,\"1823\":6496.8862304688,\"1824\":6496.8862304688,\"1825\":6496.8862304688,\"1826\":6496.8862304688,\"1827\":6496.8862304688,\"1828\":6496.8862304688,\"1829\":6496.8862304688,\"1830\":6496.8862304688,\"1831\":6496.8862304688,\"1832\":6496.8862304688,\"1833\":6496.8862304688,\"1834\":6496.8862304688,\"1835\":6496.8862304688,\"1836\":6496.8862304688,\"1837\":6496.8862304688,\"1838\":6496.8862304688,\"1839\":6496.8862304688,\"1840\":6496.8862304688,\"1841\":6496.8862304688,\"1842\":6496.8862304688,\"1843\":6496.8862304688,\"1844\":6496.8862304688,\"1845\":6496.8862304688,\"1846\":6496.8862304688,\"1847\":6496.8862304688,\"1848\":6496.8862304688,\"1849\":6496.8862304688,\"1850\":6496.8862304688,\"1851\":6496.8862304688,\"1852\":6496.8862304688,\"1853\":6496.8862304688,\"1854\":6496.8862304688,\"1855\":6496.8862304688,\"1856\":6496.8862304688,\"1857\":6496.8862304688,\"1858\":6496.8862304688,\"1859\":6496.8862304688,\"1860\":6496.8862304688,\"1861\":6496.8862304688,\"1862\":6496.8862304688,\"1863\":6496.8862304688,\"1864\":6496.8862304688,\"1865\":6496.8862304688,\"1866\":6496.8862304688,\"1867\":6496.8862304688,\"1868\":6496.8862304688,\"1869\":6496.8862304688,\"1870\":6496.8862304688,\"1871\":6496.8862304688,\"1872\":6496.8862304688,\"1873\":6496.8862304688,\"1874\":6496.8862304688,\"1875\":6496.8862304688,\"1876\":6496.8862304688,\"1877\":6496.8862304688,\"1878\":6496.8862304688,\"1879\":6496.8862304688,\"1880\":6496.8862304688,\"1881\":6496.8862304688,\"1882\":6496.8862304688,\"1883\":6496.8862304688,\"1884\":6496.8862304688,\"1885\":6496.8862304688,\"1886\":6496.8862304688,\"1887\":6496.8862304688,\"1888\":6496.8862304688,\"1889\":6496.8862304688,\"1890\":6496.8862304688,\"1891\":6496.8862304688,\"1892\":6496.8862304688,\"1893\":6496.8862304688,\"1894\":6496.8862304688,\"1895\":6496.8862304688,\"1896\":6496.8862304688,\"1897\":6496.8862304688,\"1898\":6496.8862304688,\"1899\":6496.8862304688,\"1900\":6496.8862304688,\"1901\":6496.8862304688,\"1902\":6496.8862304688,\"1903\":6496.8862304688,\"1904\":6496.8862304688,\"1905\":6496.8862304688,\"1906\":6496.8862304688,\"1907\":6496.8862304688,\"1908\":6496.8862304688,\"1909\":6496.8862304688,\"1910\":6496.8862304688,\"1911\":6496.8862304688,\"1912\":6496.8862304688,\"1913\":6496.8862304688,\"1914\":6496.8862304688,\"1915\":6496.8862304688,\"1916\":6496.8862304688,\"1917\":6496.8862304688,\"1918\":6496.8862304688,\"1919\":6496.8862304688,\"1920\":6496.8862304688,\"1921\":6496.8862304688,\"1922\":6496.8862304688,\"1923\":6496.8862304688,\"1924\":6496.8862304688,\"1925\":6496.8862304688,\"1926\":6496.8862304688,\"1927\":6496.8862304688,\"1928\":6496.8862304688,\"1929\":6496.8862304688,\"1930\":6496.8862304688,\"1931\":6496.8862304688,\"1932\":6496.8862304688,\"1933\":6496.8862304688,\"1934\":6496.8862304688,\"1935\":6496.8862304688,\"1936\":6496.8862304688,\"1937\":6496.8862304688,\"1938\":6496.8862304688,\"1939\":6496.8862304688,\"1940\":6496.8862304688,\"1941\":6496.8862304688,\"1942\":6496.8862304688,\"1943\":6496.8862304688,\"1944\":6496.8862304688,\"1945\":6496.8862304688,\"1946\":6496.8862304688,\"1947\":6496.8862304688,\"1948\":6496.8862304688,\"1949\":6496.8862304688,\"1950\":6496.8862304688,\"1951\":6496.8862304688,\"1952\":6496.8862304688,\"1953\":6496.8862304688,\"1954\":6496.8862304688,\"1955\":6496.8862304688,\"1956\":6496.8862304688,\"1957\":6496.8862304688,\"1958\":6496.8862304688,\"1959\":6496.8862304688,\"1960\":6496.8862304688,\"1961\":6496.8862304688,\"1962\":6496.8862304688,\"1963\":6496.8862304688,\"1964\":6496.8862304688,\"1965\":6496.8862304688,\"1966\":6496.8862304688,\"1967\":6496.8862304688,\"1968\":6496.8862304688,\"1969\":6496.8862304688,\"1970\":6496.8862304688,\"1971\":6496.8862304688,\"1972\":6496.8862304688,\"1973\":6496.8862304688,\"1974\":6496.8862304688,\"1975\":6496.8862304688,\"1976\":6496.8862304688,\"1977\":6496.8862304688,\"1978\":6496.8862304688,\"1979\":6496.8862304688,\"1980\":6496.8862304688,\"1981\":6496.8862304688,\"1982\":6496.8862304688,\"1983\":6496.8862304688,\"1984\":6496.8862304688,\"1985\":6496.8862304688,\"1986\":6496.8862304688,\"1987\":6496.8862304688,\"1988\":6496.8862304688,\"1989\":6496.8862304688,\"1990\":6496.8862304688,\"1991\":6496.8862304688,\"1992\":6496.8862304688,\"1993\":6496.8862304688,\"1994\":6496.8862304688,\"1995\":6496.8862304688,\"1996\":6496.8862304688,\"1997\":6496.8862304688,\"1998\":6496.8862304688,\"1999\":6496.8862304688,\"2000\":6496.8862304688,\"2001\":6496.8862304688,\"2002\":6496.8862304688,\"2003\":6496.8862304688,\"2004\":6496.8862304688,\"2005\":6496.8862304688,\"2006\":6496.8862304688,\"2007\":6496.8862304688,\"2008\":6496.8862304688,\"2009\":6496.8862304688,\"2010\":6496.8862304688,\"2011\":6496.8862304688,\"2012\":6496.8862304688,\"2013\":6496.8862304688,\"2014\":6496.8862304688,\"2015\":6496.8862304688,\"2016\":6496.8862304688,\"2017\":6496.8862304688,\"2018\":6496.8862304688,\"2019\":6496.8862304688,\"2020\":6496.8862304688,\"2021\":6496.8862304688,\"2022\":6496.8862304688,\"2023\":6496.8862304688,\"2024\":6496.8862304688,\"2025\":6496.8862304688,\"2026\":6496.8862304688,\"2027\":6496.8862304688,\"2028\":6496.8862304688,\"2029\":6496.8862304688,\"2030\":6496.8862304688,\"2031\":6496.8862304688,\"2032\":6496.8862304688,\"2033\":6496.8862304688,\"2034\":6496.8862304688,\"2035\":6496.8862304688,\"2036\":6496.8862304688,\"2037\":6496.8862304688,\"2038\":6496.8862304688,\"2039\":6496.8862304688,\"2040\":6496.8862304688,\"2041\":6496.8862304688,\"2042\":6496.8862304688,\"2043\":6496.8862304688,\"2044\":6496.8862304688,\"2045\":6496.8862304688,\"2046\":6496.8862304688,\"2047\":6496.8862304688,\"2048\":6496.8862304688,\"2049\":6496.8862304688,\"2050\":6496.8862304688,\"2051\":6496.8862304688,\"2052\":6496.8862304688,\"2053\":6496.8862304688,\"2054\":6496.8862304688,\"2055\":6496.8862304688,\"2056\":6496.8862304688,\"2057\":6496.8862304688,\"2058\":6496.8862304688,\"2059\":6496.8862304688,\"2060\":6496.8862304688,\"2061\":6496.8862304688,\"2062\":6496.8862304688,\"2063\":6496.8862304688,\"2064\":6496.8862304688,\"2065\":6496.8862304688,\"2066\":6496.8862304688,\"2067\":6496.8862304688,\"2068\":6496.8862304688,\"2069\":6496.8862304688,\"2070\":6496.8862304688,\"2071\":6496.8862304688,\"2072\":6496.8862304688,\"2073\":6496.8862304688,\"2074\":6496.8862304688,\"2075\":6496.8862304688,\"2076\":6496.8862304688,\"2077\":6496.8862304688,\"2078\":6496.8862304688,\"2079\":6496.8862304688,\"2080\":6496.8862304688,\"2081\":6496.8862304688,\"2082\":6496.8862304688,\"2083\":6496.8862304688,\"2084\":6496.8862304688,\"2085\":6496.8862304688,\"2086\":6496.8862304688,\"2087\":6496.8862304688,\"2088\":6496.8862304688,\"2089\":6496.8862304688,\"2090\":6496.8862304688,\"2091\":6496.8862304688,\"2092\":6496.8862304688,\"2093\":6496.8862304688,\"2094\":6496.8862304688,\"2095\":6496.8862304688,\"2096\":6496.8862304688,\"2097\":6496.8862304688,\"2098\":6496.8862304688,\"2099\":6496.8862304688,\"2100\":6496.8862304688,\"2101\":6496.8862304688,\"2102\":6496.8862304688,\"2103\":6496.8862304688,\"2104\":6496.8862304688,\"2105\":6496.8862304688,\"2106\":6496.8862304688,\"2107\":6496.8862304688,\"2108\":6496.8862304688,\"2109\":6496.8862304688,\"2110\":6496.8862304688,\"2111\":6496.8862304688,\"2112\":6496.8862304688,\"2113\":6496.8862304688,\"2114\":6496.8862304688,\"2115\":6496.8862304688,\"2116\":6496.8862304688,\"2117\":6496.8862304688,\"2118\":6496.8862304688,\"2119\":6496.8862304688,\"2120\":6496.8862304688,\"2121\":6496.8862304688,\"2122\":6496.8862304688,\"2123\":6496.8862304688,\"2124\":6496.8862304688,\"2125\":6496.8862304688,\"2126\":6496.8862304688,\"2127\":6496.8862304688,\"2128\":6496.8862304688,\"2129\":6496.8862304688,\"2130\":6496.8862304688,\"2131\":6496.8862304688,\"2132\":6496.8862304688,\"2133\":6496.8862304688,\"2134\":6496.8862304688,\"2135\":6496.8862304688,\"2136\":6496.8862304688,\"2137\":6496.8862304688,\"2138\":6496.8862304688,\"2139\":6496.8862304688,\"2140\":6496.8862304688,\"2141\":6496.8862304688,\"2142\":6496.8862304688,\"2143\":6496.8862304688,\"2144\":6496.8862304688,\"2145\":6496.8862304688,\"2146\":6496.8862304688,\"2147\":6496.8862304688,\"2148\":6496.8862304688,\"2149\":6496.8862304688,\"2150\":6496.8862304688,\"2151\":6496.8862304688,\"2152\":6496.8862304688,\"2153\":6496.8862304688,\"2154\":6496.8862304688,\"2155\":6496.8862304688,\"2156\":6496.8862304688,\"2157\":6496.8862304688,\"2158\":6496.8862304688,\"2159\":6496.8862304688,\"2160\":6496.8862304688,\"2161\":6496.8862304688,\"2162\":6496.8862304688,\"2163\":6496.8862304688,\"2164\":6496.8862304688,\"2165\":6496.8862304688,\"2166\":6496.8862304688,\"2167\":6496.8862304688,\"2168\":6496.8862304688,\"2169\":6496.8862304688,\"2170\":6496.8862304688,\"2171\":6496.8862304688,\"2172\":6496.8862304688,\"2173\":6496.8862304688,\"2174\":6496.8862304688,\"2175\":6496.8862304688,\"2176\":6496.8862304688,\"2177\":6496.8862304688,\"2178\":6496.8862304688,\"2179\":6496.8862304688,\"2180\":6496.8862304688,\"2181\":6496.8862304688,\"2182\":6496.8862304688,\"2183\":6496.8862304688,\"2184\":6496.8862304688,\"2185\":6496.8862304688,\"2186\":6496.8862304688,\"2187\":6496.8862304688,\"2188\":6496.8862304688,\"2189\":6496.8862304688,\"2190\":6496.8862304688,\"2191\":6496.8862304688,\"2192\":6496.8862304688,\"2193\":6496.8862304688,\"2194\":6496.8862304688,\"2195\":6496.8862304688,\"2196\":6496.8862304688,\"2197\":6496.8862304688,\"2198\":6496.8862304688,\"2199\":6496.8862304688,\"2200\":6496.8862304688,\"2201\":6496.8862304688,\"2202\":6496.8862304688,\"2203\":6496.8862304688,\"2204\":6496.8862304688,\"2205\":6496.8862304688,\"2206\":6496.8862304688,\"2207\":6496.8862304688,\"2208\":6496.8862304688,\"2209\":6496.8862304688,\"2210\":6496.8862304688,\"2211\":6496.8862304688,\"2212\":6496.8862304688,\"2213\":6496.8862304688,\"2214\":6496.8862304688,\"2215\":6496.8862304688,\"2216\":6496.8862304688,\"2217\":6496.8862304688,\"2218\":6496.8862304688,\"2219\":6496.8862304688,\"2220\":6496.8862304688,\"2221\":6496.8862304688,\"2222\":6496.8862304688,\"2223\":6496.8862304688,\"2224\":6496.8862304688,\"2225\":6496.8862304688,\"2226\":6496.8862304688,\"2227\":6496.8862304688,\"2228\":6496.8862304688,\"2229\":6496.8862304688,\"2230\":6496.8862304688,\"2231\":6496.8862304688,\"2232\":6496.8862304688,\"2233\":6496.8862304688,\"2234\":6496.8862304688,\"2235\":6496.8862304688,\"2236\":6496.8862304688,\"2237\":6496.8862304688,\"2238\":6496.8862304688,\"2239\":6496.8862304688,\"2240\":6496.8862304688,\"2241\":6496.8862304688,\"2242\":6496.8862304688,\"2243\":6496.8862304688,\"2244\":6496.8862304688,\"2245\":6496.8862304688,\"2246\":6496.8862304688,\"2247\":6496.8862304688,\"2248\":6496.8862304688,\"2249\":6496.8862304688,\"2250\":6496.8862304688,\"2251\":6496.8862304688,\"2252\":6496.8862304688,\"2253\":6496.8862304688,\"2254\":6496.8862304688,\"2255\":6496.8862304688,\"2256\":6496.8862304688,\"2257\":6496.8862304688,\"2258\":6496.8862304688,\"2259\":6496.8862304688,\"2260\":6496.8862304688,\"2261\":6496.8862304688,\"2262\":6496.8862304688,\"2263\":6496.8862304688,\"2264\":6496.8862304688,\"2265\":6496.8862304688,\"2266\":6496.8862304688,\"2267\":6496.8862304688,\"2268\":6496.8862304688,\"2269\":6496.8862304688,\"2270\":6496.8862304688,\"2271\":6496.8862304688,\"2272\":6496.8862304688,\"2273\":6496.8862304688,\"2274\":6496.8862304688,\"2275\":6496.8862304688,\"2276\":6496.8862304688,\"2277\":6496.8862304688,\"2278\":6496.8862304688,\"2279\":6496.8862304688,\"2280\":6496.8862304688,\"2281\":6496.8862304688,\"2282\":6496.8862304688,\"2283\":6496.8862304688,\"2284\":6496.8862304688,\"2285\":6496.8862304688,\"2286\":6496.8862304688,\"2287\":6496.8862304688,\"2288\":6496.8862304688,\"2289\":6496.8862304688,\"2290\":6496.8862304688,\"2291\":6496.8862304688,\"2292\":6496.8862304688,\"2293\":6496.8862304688,\"2294\":6496.8862304688,\"2295\":6496.8862304688,\"2296\":6496.8862304688,\"2297\":6496.8862304688,\"2298\":6496.8862304688,\"2299\":6496.8862304688,\"2300\":6496.8862304688,\"2301\":6496.8862304688,\"2302\":6496.8862304688,\"2303\":6496.8862304688,\"2304\":6496.8862304688,\"2305\":6496.8862304688,\"2306\":6496.8862304688,\"2307\":6496.8862304688,\"2308\":6496.8862304688,\"2309\":6496.8862304688,\"2310\":6496.8862304688,\"2311\":6496.8862304688,\"2312\":6496.8862304688,\"2313\":6496.8862304688,\"2314\":6496.8862304688,\"2315\":6496.8862304688,\"2316\":6496.8862304688,\"2317\":6496.8862304688,\"2318\":6496.8862304688,\"2319\":6496.8862304688,\"2320\":6496.8862304688,\"2321\":6496.8862304688,\"2322\":6496.8862304688,\"2323\":6496.8862304688,\"2324\":6496.8862304688,\"2325\":6496.8862304688,\"2326\":6496.8862304688,\"2327\":6496.8862304688,\"2328\":6496.8862304688,\"2329\":6496.8862304688,\"2330\":6496.8862304688,\"2331\":6496.8862304688,\"2332\":6496.8862304688,\"2333\":6496.8862304688,\"2334\":6496.8862304688,\"2335\":6496.8862304688,\"2336\":6496.8862304688,\"2337\":6496.8862304688,\"2338\":6496.8862304688,\"2339\":6496.8862304688,\"2340\":6496.8862304688,\"2341\":6496.8862304688,\"2342\":6496.8862304688,\"2343\":6496.8862304688,\"2344\":6496.8862304688,\"2345\":6496.8862304688,\"2346\":6496.8862304688,\"2347\":6496.8862304688,\"2348\":6496.8862304688,\"2349\":6496.8862304688,\"2350\":6496.8862304688,\"2351\":6496.8862304688,\"2352\":6496.8862304688,\"2353\":6496.8862304688,\"2354\":6496.8862304688,\"2355\":6496.8862304688,\"2356\":6496.8862304688,\"2357\":6496.8862304688,\"2358\":6496.8862304688,\"2359\":6496.8862304688,\"2360\":6496.8862304688,\"2361\":6496.8862304688,\"2362\":6496.8862304688,\"2363\":6496.8862304688,\"2364\":6496.8862304688,\"2365\":6496.8862304688,\"2366\":6496.8862304688,\"2367\":6496.8862304688,\"2368\":6496.8862304688,\"2369\":6496.8862304688,\"2370\":6496.8862304688,\"2371\":6496.8862304688,\"2372\":6496.8862304688,\"2373\":6496.8862304688,\"2374\":6496.8862304688,\"2375\":6496.8862304688,\"2376\":6496.8862304688,\"2377\":6496.8862304688,\"2378\":6496.8862304688,\"2379\":6496.8862304688,\"2380\":6496.8862304688,\"2381\":6496.8862304688,\"2382\":6496.8862304688,\"2383\":6496.8862304688,\"2384\":6496.8862304688,\"2385\":6496.8862304688,\"2386\":6496.8862304688,\"2387\":6496.8862304688,\"2388\":6496.8862304688,\"2389\":6496.8862304688,\"2390\":6496.8862304688,\"2391\":6496.8862304688,\"2392\":6496.8862304688,\"2393\":6496.8862304688,\"2394\":6496.8862304688,\"2395\":6496.8862304688,\"2396\":6496.8862304688,\"2397\":6496.8862304688,\"2398\":6496.8862304688,\"2399\":6496.8862304688,\"2400\":6496.8862304688,\"2401\":6496.8862304688,\"2402\":6496.8862304688,\"2403\":6496.8862304688,\"2404\":6496.8862304688,\"2405\":6496.8862304688,\"2406\":6496.8862304688,\"2407\":6496.8862304688,\"2408\":6496.8862304688,\"2409\":6496.8862304688,\"2410\":6496.8862304688,\"2411\":6496.8862304688,\"2412\":6496.8862304688,\"2413\":6496.8862304688,\"2414\":6496.8862304688,\"2415\":6496.8862304688,\"2416\":6496.8862304688,\"2417\":6496.8862304688,\"2418\":6496.8862304688,\"2419\":6496.8862304688,\"2420\":6496.8862304688,\"2421\":6496.8862304688,\"2422\":6496.8862304688,\"2423\":6496.8862304688,\"2424\":6496.8862304688,\"2425\":6496.8862304688,\"2426\":6496.8862304688,\"2427\":6496.8862304688,\"2428\":6496.8862304688,\"2429\":6496.8862304688,\"2430\":6496.8862304688,\"2431\":6496.8862304688,\"2432\":6496.8862304688,\"2433\":6496.8862304688,\"2434\":6496.8862304688,\"2435\":6496.8862304688,\"2436\":6496.8862304688,\"2437\":6496.8862304688,\"2438\":6496.8862304688,\"2439\":6496.8862304688,\"2440\":6496.8862304688,\"2441\":6496.8862304688,\"2442\":6496.8862304688,\"2443\":6496.8862304688,\"2444\":6496.8862304688,\"2445\":6496.8862304688,\"2446\":6496.8862304688,\"2447\":6496.8862304688,\"2448\":6496.8862304688,\"2449\":6496.8862304688,\"2450\":6496.8862304688,\"2451\":6496.8862304688,\"2452\":6496.8862304688,\"2453\":6496.8862304688,\"2454\":6496.8862304688,\"2455\":6496.8862304688,\"2456\":6496.8862304688,\"2457\":6496.8862304688,\"2458\":6496.8862304688,\"2459\":6496.8862304688,\"2460\":6496.8862304688,\"2461\":6496.8862304688,\"2462\":6496.8862304688,\"2463\":6496.8862304688,\"2464\":6496.8862304688,\"2465\":6496.8862304688,\"2466\":6496.8862304688,\"2467\":6496.8862304688,\"2468\":6496.8862304688,\"2469\":6496.8862304688,\"2470\":6496.8862304688,\"2471\":6496.8862304688,\"2472\":6496.8862304688,\"2473\":6496.8862304688,\"2474\":6496.8862304688,\"2475\":6496.8862304688,\"2476\":6496.8862304688,\"2477\":6496.8862304688,\"2478\":6496.8862304688,\"2479\":6496.8862304688,\"2480\":6496.8862304688,\"2481\":6496.8862304688,\"2482\":6496.8862304688,\"2483\":6496.8862304688,\"2484\":6496.8862304688,\"2485\":6496.8862304688,\"2486\":6496.8862304688,\"2487\":6496.8862304688,\"2488\":6496.8862304688,\"2489\":6496.8862304688,\"2490\":6496.8862304688,\"2491\":6496.8862304688,\"2492\":6496.8862304688,\"2493\":6496.8862304688,\"2494\":6496.8862304688,\"2495\":6496.8862304688,\"2496\":6496.8862304688,\"2497\":6496.8862304688,\"2498\":6496.8862304688,\"2499\":6496.8862304688,\"2500\":6496.8862304688,\"2501\":6496.8862304688,\"2502\":6496.8862304688,\"2503\":6496.8862304688,\"2504\":6496.8862304688,\"2505\":6496.8862304688,\"2506\":6496.8862304688,\"2507\":6496.8862304688,\"2508\":6496.8862304688,\"2509\":6496.8862304688,\"2510\":6496.8862304688,\"2511\":6496.8862304688,\"2512\":6496.8862304688,\"2513\":6496.8862304688,\"2514\":6496.8862304688,\"2515\":6496.8862304688,\"2516\":6496.8862304688,\"2517\":6496.8862304688,\"2518\":6496.8862304688,\"2519\":6496.8862304688,\"2520\":6496.8862304688,\"2521\":6496.8862304688,\"2522\":6496.8862304688,\"2523\":6496.8862304688,\"2524\":6496.8862304688,\"2525\":6496.8862304688,\"2526\":6496.8862304688,\"2527\":6496.8862304688,\"2528\":6496.8862304688,\"2529\":6496.8862304688,\"2530\":6496.8862304688,\"2531\":6496.8862304688,\"2532\":6496.8862304688,\"2533\":6496.8862304688,\"2534\":6496.8862304688,\"2535\":6496.8862304688,\"2536\":6496.8862304688,\"2537\":6496.8862304688,\"2538\":6496.8862304688,\"2539\":6496.8862304688,\"2540\":6496.8862304688,\"2541\":6496.8862304688,\"2542\":6496.8862304688,\"2543\":6496.8862304688,\"2544\":6496.8862304688,\"2545\":6496.8862304688,\"2546\":6496.8862304688,\"2547\":6496.8862304688,\"2548\":6496.8862304688,\"2549\":6496.8862304688,\"2550\":6496.8862304688,\"2551\":6496.8862304688,\"2552\":6496.8862304688,\"2553\":6496.8862304688,\"2554\":6496.8862304688,\"2555\":6496.8862304688,\"2556\":6496.8862304688,\"2557\":6496.8862304688,\"2558\":6496.8862304688,\"2559\":6496.8862304688,\"2560\":6496.8862304688,\"2561\":6496.8862304688,\"2562\":6496.8862304688,\"2563\":6496.8862304688,\"2564\":6496.8862304688,\"2565\":6496.8862304688,\"2566\":6496.8862304688,\"2567\":6496.8862304688,\"2568\":6496.8862304688,\"2569\":6496.8862304688,\"2570\":6496.8862304688,\"2571\":6496.8862304688,\"2572\":6496.8862304688,\"2573\":6496.8862304688,\"2574\":6496.8862304688,\"2575\":6496.8862304688,\"2576\":6496.8862304688,\"2577\":6496.8862304688,\"2578\":6496.8862304688,\"2579\":6496.8862304688,\"2580\":6496.8862304688,\"2581\":6496.8862304688,\"2582\":6496.8862304688,\"2583\":6496.8862304688,\"2584\":6496.8862304688,\"2585\":6496.8862304688,\"2586\":6496.8862304688,\"2587\":6496.8862304688,\"2588\":6496.8862304688,\"2589\":6496.8862304688,\"2590\":6496.8862304688,\"2591\":6496.8862304688,\"2592\":6496.8862304688,\"2593\":6496.8862304688,\"2594\":6496.8862304688,\"2595\":6496.8862304688,\"2596\":6496.8862304688,\"2597\":6496.8862304688,\"2598\":6496.8862304688,\"2599\":6496.8862304688,\"2600\":6496.8862304688,\"2601\":6496.8862304688,\"2602\":6496.8862304688,\"2603\":6496.8862304688,\"2604\":6496.8862304688,\"2605\":6496.8862304688,\"2606\":6496.8862304688,\"2607\":6496.8862304688,\"2608\":6496.8862304688,\"2609\":6496.8862304688,\"2610\":6496.8862304688,\"2611\":6496.8862304688,\"2612\":6496.8862304688,\"2613\":6496.8862304688,\"2614\":6496.8862304688,\"2615\":6496.8862304688,\"2616\":6496.8862304688,\"2617\":6496.8862304688,\"2618\":6496.8862304688,\"2619\":6496.8862304688,\"2620\":6496.8862304688,\"2621\":6496.8862304688,\"2622\":6496.8862304688,\"2623\":6496.8862304688,\"2624\":6496.8862304688,\"2625\":6496.8862304688,\"2626\":6496.8862304688,\"2627\":6496.8862304688,\"2628\":6496.8862304688,\"2629\":6496.8862304688,\"2630\":6496.8862304688,\"2631\":6496.8862304688,\"2632\":6496.8862304688,\"2633\":6496.8862304688,\"2634\":6496.8862304688,\"2635\":6496.8862304688,\"2636\":6496.8862304688,\"2637\":6496.8862304688,\"2638\":6496.8862304688,\"2639\":6496.8862304688,\"2640\":6496.8862304688,\"2641\":6496.8862304688,\"2642\":6496.8862304688,\"2643\":6496.8862304688,\"2644\":6496.8862304688,\"2645\":6496.8862304688,\"2646\":6496.8862304688,\"2647\":6496.8862304688,\"2648\":6496.8862304688,\"2649\":6496.8862304688,\"2650\":6496.8862304688,\"2651\":6496.8862304688,\"2652\":6496.8862304688,\"2653\":6496.8862304688,\"2654\":6496.8862304688,\"2655\":6496.8862304688,\"2656\":6496.8862304688,\"2657\":6496.8862304688,\"2658\":6496.8862304688,\"2659\":6496.8862304688,\"2660\":6496.8862304688,\"2661\":6496.8862304688,\"2662\":6496.8862304688,\"2663\":6496.8862304688,\"2664\":6496.8862304688,\"2665\":6496.8862304688,\"2666\":6496.8862304688,\"2667\":6496.8862304688,\"2668\":6496.8862304688,\"2669\":6496.8862304688,\"2670\":6496.8862304688,\"2671\":6496.8862304688,\"2672\":6496.8862304688,\"2673\":6496.8862304688,\"2674\":6496.8862304688,\"2675\":6496.8862304688,\"2676\":6496.8862304688,\"2677\":6496.8862304688,\"2678\":6496.8862304688,\"2679\":6496.8862304688,\"2680\":6496.8862304688,\"2681\":6496.8862304688,\"2682\":6496.8862304688,\"2683\":6496.8862304688,\"2684\":6496.8862304688,\"2685\":6496.8862304688,\"2686\":6496.8862304688,\"2687\":6496.8862304688,\"2688\":6496.8862304688,\"2689\":6496.8862304688,\"2690\":6496.8862304688,\"2691\":6496.8862304688,\"2692\":6496.8862304688,\"2693\":6496.8862304688,\"2694\":6496.8862304688,\"2695\":6496.8862304688,\"2696\":6496.8862304688,\"2697\":6496.8862304688,\"2698\":6496.8862304688,\"2699\":6496.8862304688,\"2700\":6496.8862304688,\"2701\":6496.8862304688,\"2702\":6496.8862304688,\"2703\":6496.8862304688,\"2704\":6496.8862304688,\"2705\":6496.8862304688,\"2706\":6496.8862304688,\"2707\":6496.8862304688,\"2708\":6496.8862304688,\"2709\":6496.8862304688,\"2710\":6496.8862304688,\"2711\":6496.8862304688,\"2712\":6496.8862304688,\"2713\":6496.8862304688,\"2714\":6496.8862304688,\"2715\":6496.8862304688,\"2716\":6496.8862304688,\"2717\":6496.8862304688,\"2718\":6496.8862304688,\"2719\":6496.8862304688,\"2720\":6496.8862304688,\"2721\":6496.8862304688,\"2722\":6496.8862304688,\"2723\":6496.8862304688,\"2724\":6496.8862304688,\"2725\":6496.8862304688,\"2726\":6496.8862304688,\"2727\":6496.8862304688,\"2728\":6496.8862304688,\"2729\":6496.8862304688,\"2730\":6496.8862304688,\"2731\":6496.8862304688,\"2732\":6496.8862304688,\"2733\":6496.8862304688,\"2734\":6496.8862304688,\"2735\":6496.8862304688,\"2736\":6496.8862304688,\"2737\":6496.8862304688,\"2738\":6496.8862304688,\"2739\":6496.8862304688,\"2740\":6496.8862304688,\"2741\":6496.8862304688,\"2742\":6496.8862304688,\"2743\":6496.8862304688,\"2744\":6496.8862304688,\"2745\":6496.8862304688,\"2746\":6496.8862304688,\"2747\":6496.8862304688,\"2748\":6496.8862304688,\"2749\":6496.8862304688,\"2750\":6496.8862304688,\"2751\":6496.8862304688,\"2752\":6496.8862304688,\"2753\":6496.8862304688,\"2754\":6496.8862304688,\"2755\":6496.8862304688,\"2756\":6496.8862304688,\"2757\":6496.8862304688,\"2758\":6496.8862304688,\"2759\":6496.8862304688,\"2760\":6496.8862304688,\"2761\":6496.8862304688,\"2762\":6496.8862304688,\"2763\":6496.8862304688,\"2764\":6496.8862304688,\"2765\":6496.8862304688,\"2766\":6496.8862304688,\"2767\":6496.8862304688,\"2768\":6496.8862304688,\"2769\":6496.8862304688,\"2770\":6496.8862304688,\"2771\":6496.8862304688,\"2772\":6496.8862304688}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the function which can take inputs and return prediction\n",
        "def FunctionGeneratePrediction(inp_age , inp_children):\n",
        "\n",
        "    # Creating a data frame for the model input\n",
        "    SampleInputData=pd.DataFrame(\n",
        "     data=[[inp_age , inp_children]],\n",
        "     columns=['age' , 'children'])\n",
        "\n",
        "    # Calling the function defined above using the input parameters\n",
        "    Predictions=FunctionPredictResult(InputData= SampleInputData)\n",
        "\n",
        "    # Returning the predictions\n",
        "    return(Predictions.to_json())\n",
        "\n",
        "# Function call\n",
        "FunctionGeneratePrediction( inp_age=21,\n",
        "                           inp_children=0,\n",
        "                             )"
      ],
      "metadata": {
        "id": "fY_Y6YjRBsh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Web Deployment using Flask Library/Package**\n",
        "\n",
        "**Installing the flask library required to create the API**"
      ],
      "metadata": {
        "id": "Y6byA-uTB1Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask"
      ],
      "metadata": {
        "id": "TIuiStvcCBUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Flask API**"
      ],
      "metadata": {
        "id": "z-_Wko_xCHc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy"
      ],
      "metadata": {
        "id": "wImJJ2goCMMe"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/prediction_api', methods=[\"GET\"])\n",
        "def prediction_api():\n",
        "    try:\n",
        "        # Getting the paramters from API call\n",
        "        age_value = float(request.args.get('age'))\n",
        "        children_value=float(request.args.get('children'))\n",
        "\n",
        "\n",
        "        # Calling the funtion to get predictions\n",
        "        prediction_from_api=FunctionGeneratePrediction(\n",
        "                                                       inp_age=age_value,\n",
        "                                                       inp_children=children_value\n",
        "                                                )\n",
        "\n",
        "        return (prediction_from_api)\n",
        "\n",
        "    except Exception as e:\n",
        "        return('Something is not right!:'+str(e))"
      ],
      "metadata": {
        "id": "p3zTXHR1CSfw"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Starting the API engine**"
      ],
      "metadata": {
        "id": "CyYnHnKqCYAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if __name__ ==\"__main__\":\n",
        "\n",
        "    # Hosting the API in localhost\n",
        "    app.run(host='127.0.0.1', port=9000, threaded=True, debug=True, use_reloader=False)\n",
        "    # Interrupt kernel to stop the API"
      ],
      "metadata": {
        "id": "Cb7rLc6HCi1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"Sample URL to call the API Copy and paste below URL in the web browser http://127.0.0.1:9000/prediction_api?LSTAT=4.9&RM=6.5&PTRATIO=15.3\"**\n",
        "\n"
      ],
      "metadata": {
        "id": "qJ42hYkSDGyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Desktop App deployment: Tkinter package**\n",
        "\n",
        "1. This won't work on Google Colab.\n",
        "2. Need to use PyCharm to run the code.\n",
        "3. Need to include the data file named Medical_insurance.csv.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ocIp8V40ENra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox\n",
        "import pandas as pd\n",
        "\n",
        "class InsuranceApp:\n",
        "    def __init__(self, master):\n",
        "        self.master = master\n",
        "        self.master.title('Insurance Data Options')\n",
        "\n",
        "        # Load the data from the CSV file\n",
        "        self.data = pd.read_csv('Medical_insurance.csv')\n",
        "\n",
        "        # Setup GUI layout\n",
        "        self.setup_gui()\n",
        "\n",
        "    def setup_gui(self):\n",
        "        # Button to show 'Final Price' only\n",
        "        final_price_button = ttk.Button(self.master, text=\"1. Final Price\", command=self.show_final_price)\n",
        "        final_price_button.pack(fill=tk.X, padx=5, pady=5)\n",
        "\n",
        "        # Button to show entire dataset\n",
        "        dataset_button = ttk.Button(self.master, text=\"2. Insurance Dataset\", command=self.show_dataset)\n",
        "        dataset_button.pack(fill=tk.X, padx=5, pady=5)\n",
        "\n",
        "        # Button to exit the application\n",
        "        exit_button = ttk.Button(self.master, text=\"3. Exit\", command=self.master.quit)\n",
        "        exit_button.pack(fill=tk.X, padx=5, pady=5)\n",
        "\n",
        "        # Treeview for displaying data\n",
        "        self.tree = ttk.Treeview(self.master)\n",
        "        self.tree.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
        "\n",
        "    def show_final_price(self):\n",
        "        # Clear the treeview\n",
        "        self.tree.delete(*self.tree.get_children())\n",
        "\n",
        "        # Configuring columns for 'Final Price'\n",
        "        self.tree['columns'] = ['Final Price']\n",
        "        self.tree['show'] = 'headings'\n",
        "        self.tree.heading('Final Price', text='Final Price')\n",
        "\n",
        "        # Inserting 'Final Price' data\n",
        "        for index, row in self.data.iterrows():\n",
        "            self.tree.insert(\"\", \"end\", values=[row['charges']])\n",
        "\n",
        "    def show_dataset(self):\n",
        "        # Clear the treeview\n",
        "        self.tree.delete(*self.tree.get_children())\n",
        "\n",
        "        # Configuring columns for the entire dataset\n",
        "        self.tree['columns'] = list(self.data.columns)\n",
        "        self.tree['show'] = 'headings'\n",
        "        for col in self.data.columns:\n",
        "            self.tree.heading(col, text=col)\n",
        "\n",
        "        # Inserting dataset into the treeview\n",
        "        for index, row in self.data.iterrows():\n",
        "            self.tree.insert(\"\", \"end\", values=list(row))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    root = tk.Tk()\n",
        "    app = InsuranceApp(root)\n",
        "    root.mainloop()"
      ],
      "metadata": {
        "id": "r6HkUEWLAJzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Completion of programming project**"
      ],
      "metadata": {
        "id": "Hl1fSBk8JtfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link for the github repository**\n",
        "\n",
        "https://github.com/nuhi0517/Capstone-Project_2024"
      ],
      "metadata": {
        "id": "BxPzXntLp-jY"
      }
    }
  ]
}